{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare Datasets\n",
    "\n",
    "Created by Mitas Ray on 2024-11-17.\n",
    "\n",
    "Last edited by Mitas Ray on 2024-11-20.\n",
    "\n",
    "This notebook is used to compare two datasets. The procedure is to \n",
    "1. restrict the datasets to the same datetime window\n",
    "2. perform high-level analysis on the values in the dataset\n",
    "3. train a model with these datasets and see similar accuracy results\n",
    "\n",
    "To run the notebook,\n",
    "- on linux: use `ficc_python/requirements_py310.txt`, and use `>>> pip install jupyter`\n",
    "- on mac: use `ficc_python/requirements_py310_mac_jupyter.txt`\n",
    "\n",
    "Change the following files to enable credentials and the correct working directory:\n",
    "- `automated_training_auxiliary_functions.py::get_creds(...)`\n",
    "- `ficc/app_engine/demo/server/modules/get_creds.py::get_creds(...)`\n",
    "- `automated_training_auxiliary_variables.py::WORKING_DIRECTORY`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loads the autoreload extension\n",
    "%load_ext autoreload\n",
    "# automatically reloads all imported modules when their source code changes\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 5 workers.\n",
      "INFO: Pandarallel will use standard multiprocessing data transfer (pipe) to transfer data between the main process and workers.\n",
      "Initialized pandarallel with 5 cores\n",
      "INFO: Pandarallel will run on 5 workers.\n",
      "INFO: Pandarallel will use standard multiprocessing data transfer (pipe) to transfer data between the main process and workers.\n",
      "Initialized pandarallel with 5 cores\n",
      "INFO: Pandarallel will run on 5 workers.\n",
      "INFO: Pandarallel will use standard multiprocessing data transfer (pipe) to transfer data between the main process and workers.\n",
      "Initialized pandarallel with 5 cores\n",
      "In PRODUCTION mode (to change to TESTING mode, set `TESTING` to `True`); all files and models will be saved and NUM_EPOCHS=100\n",
      "INFO: Pandarallel will run on 5 workers.\n",
      "INFO: Pandarallel will use standard multiprocessing data transfer (pipe) to transfer data between the main process and workers.\n",
      "Initialized pandarallel with 5 cores\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "\n",
    "# importing from parent directory: https://stackoverflow.com/questions/714063/importing-modules-from-parent-folder\n",
    "import sys\n",
    "sys.path.insert(0,'../')\n",
    "\n",
    "\n",
    "from ficc.utils.auxiliary_functions import get_ys_trade_history_features\n",
    "from ficc.utils.gcp_storage_functions import download_data\n",
    "from ficc.pricing.price import compute_price\n",
    "\n",
    "from automated_training_auxiliary_variables import CATEGORICAL_FEATURES, BINARY, NON_CAT_FEATURES, NUM_TRADES_IN_HISTORY_YIELD_SPREAD_MODEL, BATCH_SIZE, BUCKET_NAME, MODEL_TO_CUMULATIVE_DATA_PICKLE_FILENAME, WORKING_DIRECTORY\n",
    "from automated_training_auxiliary_functions import STORAGE_CLIENT, MODEL_NAME_TO_KERAS_MODEL, check_that_model_is_supported, fit_encoders, create_input, train_and_evaluate_model, create_summary_of_results, get_optional_arguments_for_process_data, save_model, apply_exclusions\n",
    "from set_random_seed import set_seed\n",
    "\n",
    "\n",
    "set_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working directory: /Users/mitas/ficc/ficc_python. If this is incorrect, change it in `automated_training_auxiliary_variables.py::WORKING_DIRECTORY`\n"
     ]
    }
   ],
   "source": [
    "print(f'Working directory: {WORKING_DIRECTORY}. If this is incorrect, change it in `automated_training_auxiliary_variables.py::WORKING_DIRECTORY`')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = 'yield_spread_with_similar_trades'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restrict the data between a start and end datetime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_to_datetime(datetime_as_string: datetime | str) -> datetime:\n",
    "    if isinstance(datetime_as_string, datetime): return datetime_as_string\n",
    "    string_format = '%Y-%m-%d %H:%M:%S'\n",
    "    try:\n",
    "        return datetime.strptime(datetime_as_string, string_format)\n",
    "    except Exception as e:\n",
    "        print(f'{datetime_as_string} must be in {string_format} format')\n",
    "        raise e\n",
    "\n",
    "\n",
    "def restrict_data_to_specified_time_window(data: pd.DataFrame, \n",
    "                                           datetime_column_name: str, \n",
    "                                           start_datetime: datetime | str, \n",
    "                                           end_datetime: datetime | str) -> pd.DataFrame:\n",
    "    '''Return a truncated version of `data` with values of `datetime_column_name` between \n",
    "    `start_datetime` and `end_datetime`.'''\n",
    "    start_datetime, end_datetime = string_to_datetime(start_datetime), string_to_datetime(end_datetime)\n",
    "    after_start_datetime = data[datetime_column_name] >= start_datetime\n",
    "    before_end_datetime = data[datetime_column_name] <= end_datetime\n",
    "    rows_to_keep = after_start_datetime & before_end_datetime\n",
    "    rows_remaining = rows_to_keep.sum()\n",
    "    print(f'{len(data) - rows_remaining} rows removed from the original {len(data)} rows. {rows_remaining} rows remain.')\n",
    "    return data[rows_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "may_1_start_of_day = '2024-05-01 00:00:00'\n",
    "october_1_start_of_day = '2024-10-01 00:00:00'\n",
    "october_31_end_of_day = '2024-10-31 23:59:59'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def restrict_data_on_trade_datetime(data: pd.DataFrame, start_datetime_as_string: str, end_datetime_as_string: str) -> pd.DataFrame:\n",
    "    return restrict_data_to_specified_time_window(data, 'trade_datetime', start_datetime_as_string, end_datetime_as_string)\n",
    "\n",
    "\n",
    "def restrict_data_to_october_on_trade_datetime(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    return restrict_data_on_trade_datetime(data, october_1_start_of_day, october_31_end_of_day)\n",
    "\n",
    "\n",
    "def restrict_data_from_may_to_october_on_trade_datetime(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    return restrict_data_on_trade_datetime(data, may_1_start_of_day, october_31_end_of_day)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get data from Google Cloud Storage (or locally saved files) and restrict to desired dates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILES_DIRECTORY = f'{WORKING_DIRECTORY}/files'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_data_file_path = f'{FILES_DIRECTORY}/old_data.pkl'\n",
    "if os.path.isfile(old_data_file_path):\n",
    "    old_data = pd.read_pickle(old_data_file_path)\n",
    "else:\n",
    "    old_data = download_data(STORAGE_CLIENT, BUCKET_NAME, MODEL_TO_CUMULATIVE_DATA_PICKLE_FILENAME[MODEL])\n",
    "    old_data.to_pickle(old_data_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 rows removed from the original 6419831 rows. 6419831 rows remain.\n"
     ]
    }
   ],
   "source": [
    "old_data = restrict_data_from_may_to_october_on_trade_datetime(old_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_files_from_sp_data_for_modeling_bucket(file_names: list) -> pd.DataFrame:\n",
    "    '''Download each file in `file_names` and concatenate the dataframes together.'''\n",
    "    return pd.concat([download_data(STORAGE_CLIENT, 'sp_data_for_modeling', file_name) for file_name in file_names])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data_file_path = f'{FILES_DIRECTORY}/new_data.pkl'\n",
    "if os.path.isfile(new_data_file_path):\n",
    "    new_data = pd.read_pickle(new_data_file_path)\n",
    "else:\n",
    "    new_data = download_files_from_sp_data_for_modeling_bucket(['trades_2024-05-01_to_2024-05-31.pkl', \n",
    "                                                                'trades_2024-06-01_to_2024-06-30.pkl', \n",
    "                                                                'trades_2024-07-01_to_2024-07-31.pkl', \n",
    "                                                                'trades_2024-08-01_to_2024-08-31.pkl', \n",
    "                                                                'trades_2024-09-01_to_2024-09-30.pkl', \n",
    "                                                                'trades_2024-10-01_to_2024-10-31.pkl'])\n",
    "    new_data.to_pickle(new_data_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 rows removed from the original 6463891 rows. 6463891 rows remain.\n"
     ]
    }
   ],
   "source": [
    "new_data = restrict_data_from_may_to_october_on_trade_datetime(new_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_shapes(df1: pd.DataFrame, df2: pd.DataFrame) -> None:\n",
    "    print('\\n=== Dataset Shapes ===')\n",
    "    print(f'Dataset 1 Shape: {df1.shape}')\n",
    "    print(f'Dataset 2 Shape: {df2.shape}')\n",
    "    num_rows_df1, num_rows_df2 = df1.shape[0], df2.shape[0]\n",
    "    num_rows_difference = num_rows_df1 - num_rows_df2\n",
    "    if num_rows_difference == 0:\n",
    "        print('Both datasets have the same number of rows')\n",
    "    elif num_rows_difference > 0:\n",
    "        print(f'Dataset 1 has {num_rows_difference} ({round(num_rows_difference / num_rows_df2 * 100, 3)}%) more rows than Dataset 2')\n",
    "    elif num_rows_difference < 0:\n",
    "        print(f'Dataset 2 has {abs(num_rows_difference)} ({round(abs(num_rows_difference) / num_rows_df1 * 100, 3)}%) more rows than Dataset 1')\n",
    "    else:\n",
    "        raise ValueError(f'{num_rows_difference} has a value that cannot be compared to 0')\n",
    "\n",
    "\n",
    "def compare_columns(df1: pd.DataFrame, df2: pd.DataFrame) -> None:\n",
    "    print('\\n=== Column Comparison ===')\n",
    "    print(f'Dataset 1 Columns: {sorted(df1.columns.tolist())}')\n",
    "    print(f'Dataset 2 Columns: {sorted(df2.columns.tolist())}')\n",
    "\n",
    "    print('\\n=== Common and Unique Columns ===')\n",
    "    common_cols = set(df1.columns).intersection(set(df2.columns))\n",
    "    unique_to_df1 = set(df1.columns) - set(df2.columns)\n",
    "    unique_to_df2 = set(df2.columns) - set(df1.columns)\n",
    "    print(f'Common Columns: {sorted(common_cols)}')\n",
    "    print(f'Columns only in Dataset 1: {sorted(unique_to_df1)}')\n",
    "    print(f'Columns only in Dataset 2: {sorted(unique_to_df2)}')\n",
    "\n",
    "\n",
    "def compare_data_types(df1: pd.DataFrame, df2: pd.DataFrame) -> None:\n",
    "    print('\\n=== Data Types ===')\n",
    "    print('Dataset 1 Data Types:')\n",
    "    print(df1.dtypes)\n",
    "    print('\\nDataset 2 Data Types:')\n",
    "    print(df2.dtypes)\n",
    "\n",
    "    ## below code does not work if there is a column with dtype numpy array\n",
    "    # print('\\n=== Unique Values per Column ===')\n",
    "    # print('Dataset 1 Unique Values:')\n",
    "    # print(df1.nunique())\n",
    "    # print('\\nDataset 2 Unique Values:')\n",
    "    # print(df2.nunique())\n",
    "\n",
    "\n",
    "def missing_values(df1: pd.DataFrame, df2: pd.DataFrame) -> None:\n",
    "    print('\\n=== Missing Values ===')\n",
    "    print('Dataset 1 Missing Values:')\n",
    "    missing_df1 = df1.isnull().sum()\n",
    "    print(missing_df1[missing_df1 > 0])\n",
    "    \n",
    "    print('\\nDataset 2 Missing Values:')\n",
    "    missing_df2 = df2.isnull().sum()\n",
    "    print(missing_df2[missing_df2 > 0])\n",
    "\n",
    "\n",
    "def check_last_trade_in_history(df1: pd.DataFrame, df2: pd.DataFrame) -> None:\n",
    "    print('\\n=== Last Trade in History ===')\n",
    "    columns_to_check = ['last_rtrs_control_number']\n",
    "    column_to_merge_on = 'rtrs_control_number'\n",
    "    columns_to_keep = [column_to_merge_on] + columns_to_check\n",
    "    assert all([((column in df1.columns) and (column in df2.columns)) for column in columns_to_keep]), f'Not all columns in {columns_to_keep} are present in both datasets'\n",
    "    df1, df2 = df1[columns_to_keep], df2[columns_to_keep]\n",
    "    suffix1, suffix2 = '_df1', '_df2'\n",
    "    merged_df = pd.merge(df1, df2, on=column_to_merge_on, suffixes=(suffix1, suffix2))\n",
    "    for column in columns_to_check:\n",
    "        col1, col2 = merged_df[column + suffix1], merged_df[column + suffix2]\n",
    "        differences = ~((col1.isna() & col2.isna()) | (col1 == col2))\n",
    "        print(f'{column}: {differences.sum()} rows have different values for the same {column_to_merge_on}')\n",
    "\n",
    "\n",
    "def statistical_summary(df1: pd.DataFrame, df2: pd.DataFrame) -> None:\n",
    "    '''`.describe(...)` has issues if there is a column with dtype numpy array.'''\n",
    "    print('\\n=== Statistical Summary ===')\n",
    "    print('Dataset 1 Summary:')\n",
    "    print(df1.describe(include='all'))\n",
    "    print('\\nDataset 2 Summary:')\n",
    "    print(df2.describe(include='all'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Dataset Shapes ===\n",
      "Dataset 1 Shape: (6419831, 141)\n",
      "Dataset 2 Shape: (6463891, 139)\n",
      "Dataset 2 has 44060 (0.686%) more rows than Dataset 1\n",
      "\n",
      "=== Column Comparison ===\n",
      "Dataset 1 Columns: ['A/E', 'D_min_ago_ago', 'D_min_ago_qdiff', 'D_min_ago_ttypes', 'D_min_ago_ys', 'P_min_ago_ago', 'P_min_ago_qdiff', 'P_min_ago_ttypes', 'P_min_ago_ys', 'S_min_ago_ago', 'S_min_ago_qdiff', 'S_min_ago_ttypes', 'S_min_ago_ys', 'accrual_date', 'accrued_days', 'calc_date', 'calc_day_cat', 'call_timing', 'call_timing_in_part', 'call_to_maturity', 'callable', 'callable_at_cav', 'called', 'called_redemption_type', 'capital_type', 'coupon', 'coupon_type', 'cusip', 'dated_date', 'days_in_interest_payment', 'days_to_call', 'days_to_maturity', 'days_to_par', 'days_to_refund', 'days_to_settle', 'default_indicator', 'deferred', 'delivery_date', 'dollar_price', 'escrow_exists', 'extraordinary_make_whole_call', 'federal_tax_status', 'ficc_treasury_spread', 'ficc_ycl', 'first_coupon_date', 'has_unexpired_lines_of_credit', 'incorporated_state_code', 'instrument_primary_name', 'interest_payment_frequency', 'is_callable', 'is_called', 'is_general_obligation', 'is_non_transaction_based_compensation', 'issue_amount', 'issue_price', 'issue_text', 'last_calc_date', 'last_calc_day_cat', 'last_dollar_price', 'last_ficc_ycl', 'last_maturity_date', 'last_next_call_date', 'last_par_call_date', 'last_period_accrues_from_date', 'last_refund_date', 'last_rtrs_control_number', 'last_seconds_ago', 'last_settlement_date', 'last_size', 'last_trade_date', 'last_trade_datetime', 'last_trade_type', 'last_yield', 'last_yield_spread', 'make_whole_call', 'maturity_amount', 'maturity_date', 'max_amount_outstanding', 'max_qty_ago', 'max_qty_qdiff', 'max_qty_ttypes', 'max_qty_ys', 'max_ys_ago', 'max_ys_qdiff', 'max_ys_ttypes', 'max_ys_ys', 'min_ago_ago', 'min_ago_qdiff', 'min_ago_ttypes', 'min_ago_ys', 'min_amount_outstanding', 'min_ys_ago', 'min_ys_qdiff', 'min_ys_ttypes', 'min_ys_ys', 'moodys_long', 'muni_issue_type', 'muni_security_type', 'new_ficc_ycl', 'new_ys', 'next_call_date', 'next_call_price', 'next_coupon_payment_date', 'next_sink_date', 'orig_principal_amount', 'original_yield', 'other_enhancement_type', 'par_call_date', 'par_call_price', 'par_price', 'par_traded', 'previous_coupon_payment_date', 'purpose_class', 'purpose_sub_class', 'quantity', 'rating', 'refund_date', 'rtrs_control_number', 'scaled_accrued_days', 'series_name', 'settlement_date', 'similar_trade_history', 'sink_amount_type', 'sink_frequency', 'sinking', 'sp_long', 'sp_stand_alone', 'state_tax_status', 'target_attention_features', 'trade_date', 'trade_datetime', 'trade_history', 'trade_type', 'transaction_type', 'treasury_rate', 'use_of_proceeds', 'when_issued', 'whenissued', 'yield', 'yield_spread', 'zerocoupon']\n",
      "Dataset 2 Columns: ['A/E', 'D_min_ago_ago', 'D_min_ago_qdiff', 'D_min_ago_ttypes', 'D_min_ago_ys', 'P_min_ago_ago', 'P_min_ago_qdiff', 'P_min_ago_ttypes', 'P_min_ago_ys', 'S_min_ago_ago', 'S_min_ago_qdiff', 'S_min_ago_ttypes', 'S_min_ago_ys', 'accrual_date', 'accrued_days', 'calc_date', 'calc_day_cat', 'call_timing', 'call_timing_in_part', 'call_to_maturity', 'callable', 'callable_at_cav', 'called', 'called_redemption_type', 'capital_type', 'coupon', 'coupon_type', 'cusip', 'dated_date', 'days_in_interest_payment', 'days_to_call', 'days_to_maturity', 'days_to_par', 'days_to_refund', 'days_to_settle', 'default_indicator', 'deferred', 'delivery_date', 'dollar_price', 'escrow_exists', 'extraordinary_make_whole_call', 'federal_tax_status', 'ficc_treasury_spread', 'ficc_ycl', 'first_coupon_date', 'has_unexpired_lines_of_credit', 'incorporated_state_code', 'instrument_primary_name', 'interest_payment_frequency', 'is_callable', 'is_called', 'is_general_obligation', 'is_non_transaction_based_compensation', 'issue_amount', 'issue_price', 'issue_text', 'last_calc_date', 'last_calc_day_cat', 'last_dollar_price', 'last_ficc_ycl', 'last_maturity_date', 'last_next_call_date', 'last_par_call_date', 'last_period_accrues_from_date', 'last_refund_date', 'last_rtrs_control_number', 'last_seconds_ago', 'last_settlement_date', 'last_size', 'last_trade_date', 'last_trade_datetime', 'last_trade_type', 'last_yield', 'last_yield_spread', 'make_whole_call', 'maturity_amount', 'maturity_date', 'max_amount_outstanding', 'max_qty_ago', 'max_qty_qdiff', 'max_qty_ttypes', 'max_qty_ys', 'max_ys_ago', 'max_ys_qdiff', 'max_ys_ttypes', 'max_ys_ys', 'min_ago_ago', 'min_ago_qdiff', 'min_ago_ttypes', 'min_ago_ys', 'min_amount_outstanding', 'min_ys_ago', 'min_ys_qdiff', 'min_ys_ttypes', 'min_ys_ys', 'muni_issue_type', 'muni_security_type', 'new_ficc_ycl', 'new_ys', 'next_call_date', 'next_call_price', 'next_coupon_payment_date', 'next_sink_date', 'orig_principal_amount', 'original_yield', 'other_enhancement_type', 'par_call_date', 'par_call_price', 'par_price', 'par_traded', 'previous_coupon_payment_date', 'purpose_class', 'purpose_sub_class', 'quantity', 'rating', 'refund_date', 'rtrs_control_number', 'scaled_accrued_days', 'series_name', 'settlement_date', 'similar_trade_history', 'sink_amount_type', 'sink_frequency', 'sinking', 'sp_long', 'state_tax_status', 'target_attention_features', 'trade_date', 'trade_datetime', 'trade_history', 'trade_type', 'transaction_type', 'treasury_rate', 'use_of_proceeds', 'when_issued', 'whenissued', 'yield', 'yield_spread', 'zerocoupon']\n",
      "\n",
      "=== Common and Unique Columns ===\n",
      "Common Columns: ['A/E', 'D_min_ago_ago', 'D_min_ago_qdiff', 'D_min_ago_ttypes', 'D_min_ago_ys', 'P_min_ago_ago', 'P_min_ago_qdiff', 'P_min_ago_ttypes', 'P_min_ago_ys', 'S_min_ago_ago', 'S_min_ago_qdiff', 'S_min_ago_ttypes', 'S_min_ago_ys', 'accrual_date', 'accrued_days', 'calc_date', 'calc_day_cat', 'call_timing', 'call_timing_in_part', 'call_to_maturity', 'callable', 'callable_at_cav', 'called', 'called_redemption_type', 'capital_type', 'coupon', 'coupon_type', 'cusip', 'dated_date', 'days_in_interest_payment', 'days_to_call', 'days_to_maturity', 'days_to_par', 'days_to_refund', 'days_to_settle', 'default_indicator', 'deferred', 'delivery_date', 'dollar_price', 'escrow_exists', 'extraordinary_make_whole_call', 'federal_tax_status', 'ficc_treasury_spread', 'ficc_ycl', 'first_coupon_date', 'has_unexpired_lines_of_credit', 'incorporated_state_code', 'instrument_primary_name', 'interest_payment_frequency', 'is_callable', 'is_called', 'is_general_obligation', 'is_non_transaction_based_compensation', 'issue_amount', 'issue_price', 'issue_text', 'last_calc_date', 'last_calc_day_cat', 'last_dollar_price', 'last_ficc_ycl', 'last_maturity_date', 'last_next_call_date', 'last_par_call_date', 'last_period_accrues_from_date', 'last_refund_date', 'last_rtrs_control_number', 'last_seconds_ago', 'last_settlement_date', 'last_size', 'last_trade_date', 'last_trade_datetime', 'last_trade_type', 'last_yield', 'last_yield_spread', 'make_whole_call', 'maturity_amount', 'maturity_date', 'max_amount_outstanding', 'max_qty_ago', 'max_qty_qdiff', 'max_qty_ttypes', 'max_qty_ys', 'max_ys_ago', 'max_ys_qdiff', 'max_ys_ttypes', 'max_ys_ys', 'min_ago_ago', 'min_ago_qdiff', 'min_ago_ttypes', 'min_ago_ys', 'min_amount_outstanding', 'min_ys_ago', 'min_ys_qdiff', 'min_ys_ttypes', 'min_ys_ys', 'muni_issue_type', 'muni_security_type', 'new_ficc_ycl', 'new_ys', 'next_call_date', 'next_call_price', 'next_coupon_payment_date', 'next_sink_date', 'orig_principal_amount', 'original_yield', 'other_enhancement_type', 'par_call_date', 'par_call_price', 'par_price', 'par_traded', 'previous_coupon_payment_date', 'purpose_class', 'purpose_sub_class', 'quantity', 'rating', 'refund_date', 'rtrs_control_number', 'scaled_accrued_days', 'series_name', 'settlement_date', 'similar_trade_history', 'sink_amount_type', 'sink_frequency', 'sinking', 'sp_long', 'state_tax_status', 'target_attention_features', 'trade_date', 'trade_datetime', 'trade_history', 'trade_type', 'transaction_type', 'treasury_rate', 'use_of_proceeds', 'when_issued', 'whenissued', 'yield', 'yield_spread', 'zerocoupon']\n",
      "Columns only in Dataset 1: ['moodys_long', 'sp_stand_alone']\n",
      "Columns only in Dataset 2: []\n",
      "\n",
      "=== Missing Values ===\n",
      "Dataset 1 Missing Values:\n",
      "refund_date                      6178845\n",
      "next_sink_date                   5071097\n",
      "par_call_date                    2101210\n",
      "next_call_date                   2097316\n",
      "purpose_sub_class                1360240\n",
      "previous_coupon_payment_date      951110\n",
      "instrument_primary_name              284\n",
      "original_yield                      7187\n",
      "moodys_long                      1771008\n",
      "use_of_proceeds                       30\n",
      "muni_issue_type                  6152731\n",
      "other_enhancement_type           5524583\n",
      "next_coupon_payment_date              10\n",
      "first_coupon_date                      1\n",
      "last_period_accrues_from_date      87720\n",
      "last_ficc_ycl                     157589\n",
      "last_rtrs_control_number          157589\n",
      "last_yield                        157589\n",
      "last_size                         157589\n",
      "last_calc_date                    157589\n",
      "last_maturity_date                157589\n",
      "last_next_call_date              2188720\n",
      "last_par_call_date               2192293\n",
      "last_refund_date                 6187579\n",
      "last_trade_datetime               157589\n",
      "last_calc_day_cat                 157589\n",
      "last_settlement_date              157589\n",
      "last_trade_type                   157589\n",
      "last_trade_date                   157589\n",
      "dtype: int64\n",
      "\n",
      "Dataset 2 Missing Values:\n",
      "refund_date                      6244078\n",
      "next_sink_date                   5120737\n",
      "delivery_date                         75\n",
      "par_call_date                    2106888\n",
      "next_call_date                   2098456\n",
      "purpose_sub_class                 737874\n",
      "previous_coupon_payment_date      842108\n",
      "instrument_primary_name              126\n",
      "original_yield                     12916\n",
      "use_of_proceeds                        8\n",
      "muni_issue_type                  6324354\n",
      "other_enhancement_type           5942843\n",
      "next_coupon_payment_date          319947\n",
      "first_coupon_date                     31\n",
      "last_period_accrues_from_date      97437\n",
      "last_ficc_ycl                     178028\n",
      "last_rtrs_control_number          178028\n",
      "last_yield                        178028\n",
      "last_size                         178028\n",
      "last_calc_date                    178028\n",
      "last_maturity_date                178028\n",
      "last_next_call_date              2216371\n",
      "last_par_call_date               2220026\n",
      "last_refund_date                 6231574\n",
      "last_trade_datetime               178028\n",
      "last_calc_day_cat                 178028\n",
      "last_settlement_date              178028\n",
      "last_trade_type                   178028\n",
      "last_trade_date                   178028\n",
      "dtype: int64\n",
      "\n",
      "=== Last Trade in History ===\n",
      "last_rtrs_control_number: 6739 rows have different values for the same rtrs_control_number\n"
     ]
    }
   ],
   "source": [
    "compare_shapes(old_data, new_data)\n",
    "compare_columns(old_data, new_data)\n",
    "# compare_data_types(old_data, new_data)\n",
    "missing_values(old_data, new_data)\n",
    "check_last_trade_in_history(old_data, new_data)\n",
    "# statistical_summary(old_data, new_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train yield spread with similar trades model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_features_for_each_trade_in_history() -> int:\n",
    "    optional_arguments_for_process_data = get_optional_arguments_for_process_data(MODEL)\n",
    "    use_treasury_spread = optional_arguments_for_process_data.get('use_treasury_spread', False)\n",
    "    trade_history_features = get_ys_trade_history_features(use_treasury_spread)\n",
    "    return len(trade_history_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(data: pd.DataFrame, \n",
    "                last_trade_date_for_training_dataset: str, \n",
    "                model_file_path: str):\n",
    "    '''Heavily inspired by `automated_trianing_auxiliary_functions::train_model(...)`. The main changes are: \n",
    "    (1) assume that we are using the yield spread with similar trades model,\n",
    "    (2) do not have an exclusions function\n",
    "    (3) do not restrict the test set to just a single day\n",
    "    '''\n",
    "    check_that_model_is_supported(MODEL)\n",
    "    encoders, fmax = fit_encoders(data, CATEGORICAL_FEATURES, MODEL)\n",
    "    test_data = data[data.trade_date > last_trade_date_for_training_dataset]    # `test_data` can only contain trades after `last_trade_date_for_training_dataset`\n",
    "    train_data = data[data.trade_date <= last_trade_date_for_training_dataset]    # `train_data` only contains trades before and including `last_trade_date_for_training_dataset`\n",
    "    training_set_info = f'Training set contains {len(train_data)} trades ranging from trade datetimes of {train_data.trade_datetime.min()} to {train_data.trade_datetime.max()}'\n",
    "    test_set_info = f'Test set contains {len(test_data)} trades ranging from trade datetimes of {test_data.trade_datetime.min()} to {test_data.trade_datetime.max()}'\n",
    "    print(training_set_info)\n",
    "    print(test_set_info)\n",
    "\n",
    "    x_train, y_train = create_input(train_data, encoders, MODEL)\n",
    "    x_test, y_test = create_input(test_data, encoders, MODEL)\n",
    "\n",
    "    keras_model = MODEL_NAME_TO_KERAS_MODEL[MODEL]\n",
    "    untrained_model = keras_model(x_train, \n",
    "                                  NUM_TRADES_IN_HISTORY_YIELD_SPREAD_MODEL, \n",
    "                                  get_num_features_for_each_trade_in_history(), \n",
    "                                  CATEGORICAL_FEATURES, \n",
    "                                  NON_CAT_FEATURES, \n",
    "                                  BINARY, \n",
    "                                  fmax)\n",
    "    trained_model, mae, history = train_and_evaluate_model(untrained_model, x_train, y_train, x_test, y_test)\n",
    "    result_df = create_summary_of_results(trained_model, test_data, x_test, y_test)\n",
    "    save_model(trained_model, None, MODEL, model_file_path, upload_to_google_cloud_bucket=False)    # setting `encoders=None` to not save the encoders file\n",
    "    return result_df, trained_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model_directory = f'{WORKING_DIRECTORY}/files/saved_models/data_2024-05-01_2024-10-31'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trained_model(data: pd.DataFrame, last_trade_date_for_training_dataset: str, model_file_path: str) -> keras.Model:\n",
    "    '''Train the model if it does not exist in `model_file_path`. Otherwise, load the model.'''\n",
    "    if os.path.isdir(model_file_path):\n",
    "        encoders, _ = fit_encoders(data, CATEGORICAL_FEATURES, MODEL)\n",
    "        trained_model = keras.models.load_model(model_file_path)\n",
    "        test_data = data[data.trade_date > last_trade_date_for_training_dataset]\n",
    "        x_test, y_test = create_input(test_data, encoders, MODEL)\n",
    "        result_df = create_summary_of_results(trained_model, test_data, x_test, y_test)\n",
    "    else:\n",
    "        result_df, trained_model = train_model(data, last_trade_date_for_training_dataset, model_file_path)\n",
    "    return result_df, trained_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEGIN create_input\n",
      "END create_input. Execution time: 0:00:05.486\n",
      "   1/1163 [..............................] - ETA: 23:25"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-20 17:27:45.329231: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:693] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"CPU\" model: \"0\" frequency: 2400 num_cores: 10 environment { key: \"cpu_instruction_set\" value: \"ARM NEON\" } environment { key: \"eigen\" value: \"3.4.90\" } l1_cache_size: 16384 l2_cache_size: 524288 l3_cache_size: 524288 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1163/1163 [==============================] - 29s 24ms/step\n",
      "|                                 |   Mean Absolute Error |      Trade Count |\n",
      "|:--------------------------------|----------------------:|-----------------:|\n",
      "| Entire set                      |                12.838 |      1.16204e+06 |\n",
      "| Dealer-Dealer                   |                13.175 | 438706           |\n",
      "| Bid Side / Dealer-Purchase      |                14.134 | 302777           |\n",
      "| Offered Side / Dealer-Sell      |                11.553 | 420553           |\n",
      "| AAA                             |                12.002 | 190193           |\n",
      "| Investment Grade                |                12.528 | 937855           |\n",
      "| Trade size >= 100k              |                11.099 | 262298           |\n",
      "| Last trade <= 7 days            |                10.957 | 794632           |\n",
      "| 7 days < Last trade <= 14 days  |                13.789 | 109307           |\n",
      "| 14 days < Last trade <= 28 days |                15.924 |  88850           |\n",
      "| 28 days < Last trade            |                19.433 | 169247           |\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean Absolute Error</th>\n",
       "      <th>Trade Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Entire set</th>\n",
       "      <td>12.838</td>\n",
       "      <td>1162036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dealer-Dealer</th>\n",
       "      <td>13.175</td>\n",
       "      <td>438706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bid Side / Dealer-Purchase</th>\n",
       "      <td>14.134</td>\n",
       "      <td>302777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Offered Side / Dealer-Sell</th>\n",
       "      <td>11.553</td>\n",
       "      <td>420553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAA</th>\n",
       "      <td>12.002</td>\n",
       "      <td>190193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Investment Grade</th>\n",
       "      <td>12.528</td>\n",
       "      <td>937855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trade size &gt;= 100k</th>\n",
       "      <td>11.099</td>\n",
       "      <td>262298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Last trade &lt;= 7 days</th>\n",
       "      <td>10.957</td>\n",
       "      <td>794632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7 days &lt; Last trade &lt;= 14 days</th>\n",
       "      <td>13.789</td>\n",
       "      <td>109307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14 days &lt; Last trade &lt;= 28 days</th>\n",
       "      <td>15.924</td>\n",
       "      <td>88850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28 days &lt; Last trade</th>\n",
       "      <td>19.433</td>\n",
       "      <td>169247</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Mean Absolute Error  Trade Count\n",
       "Entire set                                    12.838      1162036\n",
       "Dealer-Dealer                                 13.175       438706\n",
       "Bid Side / Dealer-Purchase                    14.134       302777\n",
       "Offered Side / Dealer-Sell                    11.553       420553\n",
       "AAA                                           12.002       190193\n",
       "Investment Grade                              12.528       937855\n",
       "Trade size >= 100k                            11.099       262298\n",
       "Last trade <= 7 days                          10.957       794632\n",
       "7 days < Last trade <= 14 days                13.789       109307\n",
       "14 days < Last trade <= 28 days               15.924        88850\n",
       "28 days < Last trade                          19.433       169247"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df, model_old_data = get_trained_model(old_data, '2024-09-30', f'{saved_model_directory}/old_data_2024-11-19')    # Tuesday 2024-10-01 - Thursday 2024-10-31 is the test set\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEGIN create_input\n",
      "END create_input. Execution time: 0:00:05.006\n",
      "   1/1168 [..............................] - ETA: 21:48"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-20 17:29:17.917787: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:693] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"CPU\" model: \"0\" frequency: 2400 num_cores: 10 environment { key: \"cpu_instruction_set\" value: \"ARM NEON\" } environment { key: \"eigen\" value: \"3.4.90\" } l1_cache_size: 16384 l2_cache_size: 524288 l3_cache_size: 524288 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1168/1168 [==============================] - 28s 23ms/step\n",
      "|                                 |   Mean Absolute Error |      Trade Count |\n",
      "|:--------------------------------|----------------------:|-----------------:|\n",
      "| Entire set                      |                12.829 |      1.16723e+06 |\n",
      "| Dealer-Dealer                   |                13.188 | 439702           |\n",
      "| Bid Side / Dealer-Purchase      |                14.255 | 302799           |\n",
      "| Offered Side / Dealer-Sell      |                11.44  | 424731           |\n",
      "| AAA                             |                11.924 | 176956           |\n",
      "| Investment Grade                |                12.584 | 862236           |\n",
      "| Trade size >= 100k              |                10.861 | 266471           |\n",
      "| Last trade <= 7 days            |                10.952 | 800077           |\n",
      "| 7 days < Last trade <= 14 days  |                14.261 | 109229           |\n",
      "| 14 days < Last trade <= 28 days |                16.573 |  88791           |\n",
      "| 28 days < Last trade            |                18.817 | 169135           |\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean Absolute Error</th>\n",
       "      <th>Trade Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Entire set</th>\n",
       "      <td>12.829</td>\n",
       "      <td>1167232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dealer-Dealer</th>\n",
       "      <td>13.188</td>\n",
       "      <td>439702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bid Side / Dealer-Purchase</th>\n",
       "      <td>14.255</td>\n",
       "      <td>302799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Offered Side / Dealer-Sell</th>\n",
       "      <td>11.440</td>\n",
       "      <td>424731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAA</th>\n",
       "      <td>11.924</td>\n",
       "      <td>176956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Investment Grade</th>\n",
       "      <td>12.584</td>\n",
       "      <td>862236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trade size &gt;= 100k</th>\n",
       "      <td>10.861</td>\n",
       "      <td>266471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Last trade &lt;= 7 days</th>\n",
       "      <td>10.952</td>\n",
       "      <td>800077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7 days &lt; Last trade &lt;= 14 days</th>\n",
       "      <td>14.261</td>\n",
       "      <td>109229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14 days &lt; Last trade &lt;= 28 days</th>\n",
       "      <td>16.573</td>\n",
       "      <td>88791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28 days &lt; Last trade</th>\n",
       "      <td>18.817</td>\n",
       "      <td>169135</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Mean Absolute Error  Trade Count\n",
       "Entire set                                    12.829      1167232\n",
       "Dealer-Dealer                                 13.188       439702\n",
       "Bid Side / Dealer-Purchase                    14.255       302799\n",
       "Offered Side / Dealer-Sell                    11.440       424731\n",
       "AAA                                           11.924       176956\n",
       "Investment Grade                              12.584       862236\n",
       "Trade size >= 100k                            10.861       266471\n",
       "Last trade <= 7 days                          10.952       800077\n",
       "7 days < Last trade <= 14 days                14.261       109229\n",
       "14 days < Last trade <= 28 days               16.573        88791\n",
       "28 days < Last trade                          18.817       169135"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df, model_new_data = get_trained_model(new_data, '2024-09-30', f'{saved_model_directory}/new_data_2024-11-19')    # Tuesday 2024-10-01 - Thursday 2024-10-31 is the test set\n",
    "result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform yield to price conversion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_yield_spread_predictions(data: pd.DataFrame, model: keras.Model) -> np.ndarray:\n",
    "    '''Returns yield spread predictions based on calling `model` with `data`.'''\n",
    "    encoders, _ = fit_encoders(data, CATEGORICAL_FEATURES, MODEL)\n",
    "    inputs, _ = create_input(data, encoders, MODEL, ignore_label=True)\n",
    "    yield_spread_predictions = model.predict(inputs, batch_size=BATCH_SIZE).flatten()\n",
    "    return yield_spread_predictions\n",
    "\n",
    "\n",
    "def get_dollar_price_conversions(data: pd.DataFrame, yield_spread_predictions: np.ndarray) -> np.ndarray:\n",
    "    '''Returns dollar price conversions of yields resulting from adding the ficc yield curve \n",
    "    level to the predicted yield spread.'''\n",
    "    yield_predictions = yield_spread_predictions + data['ficc_ycl']\n",
    "    # assert 'ficc_ytw' not in data.columns, f'ficc_ytw is already a column in the inputted dataframe'\n",
    "    data['ficc_ytw'] = yield_predictions\n",
    "\n",
    "    call_defeased_not_in_columns = 'call_defeased' not in data.columns\n",
    "    if call_defeased_not_in_columns: data['call_defeased'] = True    # add `call_defeased` since it is needed to convert yield to price, but it is not very common, and so Jesse suggests setting it to `True` to make this work (also because MSRB does not use it, and further downstream, we compare our converted prices to MSRB dollar prices)\n",
    "    converted_dollar_prices = data.apply(lambda row: compute_price(row)[0], axis=1)    # using index 0 because the first item is the dollar price and the second item is the calc date\n",
    "    data = data.drop(columns='ficc_ytw')\n",
    "    if call_defeased_not_in_columns: data.drop(columns='call_defeased')\n",
    "    return converted_dollar_prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEGIN create_input\n",
      "END create_input. Execution time: 0:00:35.158\n",
      "6420/6420 [==============================] - 151s 23ms/step\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute 'refund_price'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [23], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m old_data_yield_spreads \u001b[38;5;241m=\u001b[39m get_yield_spread_predictions(old_data, model_old_data)\n\u001b[0;32m----> 2\u001b[0m old_data_dollar_prices \u001b[38;5;241m=\u001b[39m \u001b[43mget_dollar_price_conversions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mold_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mold_data_yield_spreads\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn [22], line 18\u001b[0m, in \u001b[0;36mget_dollar_price_conversions\u001b[0;34m(data, yield_spread_predictions)\u001b[0m\n\u001b[1;32m     16\u001b[0m call_defeased_not_in_columns \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcall_defeased\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m data\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m call_defeased_not_in_columns: data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcall_defeased\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m    \u001b[38;5;66;03m# add `call_defeased` since it is needed to convert yield to price, but it is not very common, and so Jesse suggests setting it to `True` to make this work (also because MSRB does not use it, and further downstream, we compare our converted prices to MSRB dollar prices)\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m converted_dollar_prices \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompute_price\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m    \u001b[38;5;66;03m# using index 0 because the first item is the dollar price and the second item is the calc date\u001b[39;00m\n\u001b[1;32m     19\u001b[0m data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mficc_ytw\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m call_defeased_not_in_columns: data\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcall_defeased\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/ficc/ficc_python/venv_py310/lib/python3.10/site-packages/pandas/core/frame.py:9568\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[0;34m(self, func, axis, raw, result_type, args, **kwargs)\u001b[0m\n\u001b[1;32m   9557\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[1;32m   9559\u001b[0m op \u001b[38;5;241m=\u001b[39m frame_apply(\n\u001b[1;32m   9560\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   9561\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   9566\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[1;32m   9567\u001b[0m )\n\u001b[0;32m-> 9568\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/ficc/ficc_python/venv_py310/lib/python3.10/site-packages/pandas/core/apply.py:764\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw:\n\u001b[1;32m    762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_raw()\n\u001b[0;32m--> 764\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ficc/ficc_python/venv_py310/lib/python3.10/site-packages/pandas/core/apply.py:891\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    890\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 891\u001b[0m     results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_series_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    893\u001b[0m     \u001b[38;5;66;03m# wrap results\u001b[39;00m\n\u001b[1;32m    894\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrap_results(results, res_index)\n",
      "File \u001b[0;32m~/ficc/ficc_python/venv_py310/lib/python3.10/site-packages/pandas/core/apply.py:907\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    904\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    905\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[1;32m    906\u001b[0m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[0;32m--> 907\u001b[0m         results[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    908\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[1;32m    909\u001b[0m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[1;32m    910\u001b[0m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[1;32m    911\u001b[0m             results[i] \u001b[38;5;241m=\u001b[39m results[i]\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn [22], line 18\u001b[0m, in \u001b[0;36mget_dollar_price_conversions.<locals>.<lambda>\u001b[0;34m(row)\u001b[0m\n\u001b[1;32m     16\u001b[0m call_defeased_not_in_columns \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcall_defeased\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m data\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m call_defeased_not_in_columns: data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcall_defeased\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m    \u001b[38;5;66;03m# add `call_defeased` since it is needed to convert yield to price, but it is not very common, and so Jesse suggests setting it to `True` to make this work (also because MSRB does not use it, and further downstream, we compare our converted prices to MSRB dollar prices)\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m converted_dollar_prices \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m row: \u001b[43mcompute_price\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)    \u001b[38;5;66;03m# using index 0 because the first item is the dollar price and the second item is the calc date\u001b[39;00m\n\u001b[1;32m     19\u001b[0m data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mficc_ytw\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m call_defeased_not_in_columns: data\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcall_defeased\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/ficc/ficc_python/ficc/pricing/price.py:153\u001b[0m, in \u001b[0;36mcompute_price\u001b[0;34m(trade, yield_rate)\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBond (CUSIP: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrade\u001b[38;5;241m.\u001b[39mcusip\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) has an end date (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mend_date\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) which is before the settlement date (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrade\u001b[38;5;241m.\u001b[39msettlement_date\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m).\u001b[39m\u001b[38;5;124m'\u001b[39m)    \u001b[38;5;66;03m# printing instead of raising an error to not disrupt processing large quantities of trades; remove RTRS control number since new pipeline does not have it\u001b[39;00m\n\u001b[1;32m    151\u001b[0m         \u001b[38;5;66;03m# raise ValueError(f'Bond (CUSIP: {trade.cusip}, RTRS: {trade.rtrs_control_number}) has an end date ({end_date}) which is after the settlement date ({trade.settlement_date}).')\u001b[39;00m\n\u001b[0;32m--> 153\u001b[0m     redemption_value_at_refund \u001b[38;5;241m=\u001b[39m \u001b[43mrefund_price_for_called_bond\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrade\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    154\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m get_price_caller(end_date, redemption_value_at_refund), end_date\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/ficc/ficc_python/ficc/pricing/called_trade.py:21\u001b[0m, in \u001b[0;36mrefund_price_for_called_bond\u001b[0;34m(trade)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrefund_price_for_called_bond\u001b[39m(trade):\n\u001b[1;32m     20\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''This function provides the par value for a called bond.'''\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m pd\u001b[38;5;241m.\u001b[39misnull(\u001b[43mtrade\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrefund_price\u001b[49m):\n\u001b[1;32m     22\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trade\u001b[38;5;241m.\u001b[39mrefund_price\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/ficc/ficc_python/venv_py310/lib/python3.10/site-packages/pandas/core/generic.py:5902\u001b[0m, in \u001b[0;36mNDFrame.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5895\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   5896\u001b[0m     name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_names_set\n\u001b[1;32m   5897\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metadata\n\u001b[1;32m   5898\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessors\n\u001b[1;32m   5899\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info_axis\u001b[38;5;241m.\u001b[39m_can_hold_identifiers_and_holds_name(name)\n\u001b[1;32m   5900\u001b[0m ):\n\u001b[1;32m   5901\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[name]\n\u001b[0;32m-> 5902\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mobject\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getattribute__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Series' object has no attribute 'refund_price'"
     ]
    }
   ],
   "source": [
    "old_data_yield_spreads = get_yield_spread_predictions(old_data, model_old_data)\n",
    "old_data_dollar_prices = get_dollar_price_conversions(old_data, old_data_yield_spreads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bond (CUSIP: 241722ER4) has an end date (2024-08-15 00:00:00) which is before the settlement date (2024-08-28 00:00:00).\n",
      "Bond (CUSIP: 241722ER4) has an end date (2024-08-15 00:00:00) which is before the settlement date (2024-08-27 00:00:00).\n",
      "Bond (CUSIP: 241722ER4) has an end date (2024-08-15 00:00:00) which is before the settlement date (2024-08-27 00:00:00).\n",
      "Bond (CUSIP: 241722EV5) has an end date (2024-08-15 00:00:00) which is before the settlement date (2024-08-28 00:00:00).\n",
      "Bond (CUSIP: 241722EV5) has an end date (2024-08-15 00:00:00) which is before the settlement date (2024-08-28 00:00:00).\n",
      "Bond (CUSIP: 241722ES2) has an end date (2024-08-15 00:00:00) which is before the settlement date (2024-08-27 00:00:00).\n",
      "Bond (CUSIP: 241722ES2) has an end date (2024-08-15 00:00:00) which is before the settlement date (2024-08-27 00:00:00).\n",
      "Bond (CUSIP: 241722EV5) has an end date (2024-08-15 00:00:00) which is before the settlement date (2024-08-27 00:00:00).\n",
      "Bond (CUSIP: 241722EV5) has an end date (2024-08-15 00:00:00) which is before the settlement date (2024-08-27 00:00:00).\n",
      "Bond (CUSIP: 241722EV5) has an end date (2024-08-15 00:00:00) which is before the settlement date (2024-08-27 00:00:00).\n",
      "Bond (CUSIP: 241722ET0) has an end date (2024-08-15 00:00:00) which is before the settlement date (2024-08-27 00:00:00).\n",
      "Bond (CUSIP: 241722ET0) has an end date (2024-08-15 00:00:00) which is before the settlement date (2024-08-27 00:00:00).\n",
      "Bond (CUSIP: 241722ET0) has an end date (2024-08-15 00:00:00) which is before the settlement date (2024-08-27 00:00:00).\n",
      "Bond (CUSIP: 241722EZ6) has an end date (2024-08-15 00:00:00) which is before the settlement date (2024-08-27 00:00:00).\n",
      "Bond (CUSIP: 241722EZ6) has an end date (2024-08-15 00:00:00) which is before the settlement date (2024-08-27 00:00:00).\n",
      "Bond (CUSIP: 241722EZ6) has an end date (2024-08-15 00:00:00) which is before the settlement date (2024-08-27 00:00:00).\n",
      "Bond (CUSIP: 241722EU7) has an end date (2024-08-15 00:00:00) which is before the settlement date (2024-08-27 00:00:00).\n",
      "Bond (CUSIP: 241722EU7) has an end date (2024-08-15 00:00:00) which is before the settlement date (2024-08-27 00:00:00).\n",
      "Bond (CUSIP: 241722EZ6) has an end date (2024-08-15 00:00:00) which is before the settlement date (2024-08-26 00:00:00).\n",
      "Bond (CUSIP: 241722EZ6) has an end date (2024-08-15 00:00:00) which is before the settlement date (2024-08-26 00:00:00).\n",
      "Bond (CUSIP: 241722EU7) has an end date (2024-08-15 00:00:00) which is before the settlement date (2024-08-26 00:00:00).\n",
      "Bond (CUSIP: 241722EU7) has an end date (2024-08-15 00:00:00) which is before the settlement date (2024-08-26 00:00:00).\n"
     ]
    }
   ],
   "source": [
    "old_data['refund_price'] = 100\n",
    "old_data_dollar_prices = get_dollar_price_conversions(old_data, old_data_yield_spreads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEGIN create_input\n",
      "END create_input. Execution time: 0:00:50.560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-20 20:15:20.154396: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:693] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"CPU\" model: \"0\" frequency: 2400 num_cores: 10 environment { key: \"cpu_instruction_set\" value: \"ARM NEON\" } environment { key: \"eigen\" value: \"3.4.90\" } l1_cache_size: 16384 l2_cache_size: 524288 l3_cache_size: 524288 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6464/6464 [==============================] - 162s 25ms/step\n",
      "Bond (CUSIP: 748508GM4) has an end date (2024-07-15 00:00:00) which is before the settlement date (2024-08-01 00:00:00).\n",
      "Bond (CUSIP: 748508GM4) has an end date (2024-07-15 00:00:00) which is before the settlement date (2024-08-01 00:00:00).\n",
      "Bond (CUSIP: 748508GM4) has an end date (2024-07-15 00:00:00) which is before the settlement date (2024-08-01 00:00:00).\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for -: 'NaTType' and 'datetime.date'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [27], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m new_data_yield_spreads \u001b[38;5;241m=\u001b[39m get_yield_spread_predictions(new_data, model_new_data)\n\u001b[1;32m      2\u001b[0m new_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrefund_price\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m\n\u001b[0;32m----> 3\u001b[0m new_data_dollar_prices \u001b[38;5;241m=\u001b[39m \u001b[43mget_dollar_price_conversions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_data_yield_spreads\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn [25], line 18\u001b[0m, in \u001b[0;36mget_dollar_price_conversions\u001b[0;34m(data, yield_spread_predictions)\u001b[0m\n\u001b[1;32m     16\u001b[0m call_defeased_not_in_columns \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcall_defeased\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m data\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m call_defeased_not_in_columns: data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcall_defeased\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m    \u001b[38;5;66;03m# add `call_defeased` since it is needed to convert yield to price, but it is not very common, and so Jesse suggests setting it to `True` to make this work (also because MSRB does not use it, and further downstream, we compare our converted prices to MSRB dollar prices)\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m converted_dollar_prices \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompute_price\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m    \u001b[38;5;66;03m# using index 0 because the first item is the dollar price and the second item is the calc date\u001b[39;00m\n\u001b[1;32m     19\u001b[0m data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mficc_ytw\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m call_defeased_not_in_columns: data\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcall_defeased\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/ficc/ficc_python/venv_py310/lib/python3.10/site-packages/pandas/core/frame.py:9568\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[0;34m(self, func, axis, raw, result_type, args, **kwargs)\u001b[0m\n\u001b[1;32m   9557\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[1;32m   9559\u001b[0m op \u001b[38;5;241m=\u001b[39m frame_apply(\n\u001b[1;32m   9560\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   9561\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   9566\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[1;32m   9567\u001b[0m )\n\u001b[0;32m-> 9568\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/ficc/ficc_python/venv_py310/lib/python3.10/site-packages/pandas/core/apply.py:764\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw:\n\u001b[1;32m    762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_raw()\n\u001b[0;32m--> 764\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ficc/ficc_python/venv_py310/lib/python3.10/site-packages/pandas/core/apply.py:891\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    890\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 891\u001b[0m     results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_series_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    893\u001b[0m     \u001b[38;5;66;03m# wrap results\u001b[39;00m\n\u001b[1;32m    894\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrap_results(results, res_index)\n",
      "File \u001b[0;32m~/ficc/ficc_python/venv_py310/lib/python3.10/site-packages/pandas/core/apply.py:907\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    904\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    905\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[1;32m    906\u001b[0m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[0;32m--> 907\u001b[0m         results[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    908\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[1;32m    909\u001b[0m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[1;32m    910\u001b[0m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[1;32m    911\u001b[0m             results[i] \u001b[38;5;241m=\u001b[39m results[i]\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn [25], line 18\u001b[0m, in \u001b[0;36mget_dollar_price_conversions.<locals>.<lambda>\u001b[0;34m(row)\u001b[0m\n\u001b[1;32m     16\u001b[0m call_defeased_not_in_columns \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcall_defeased\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m data\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m call_defeased_not_in_columns: data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcall_defeased\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m    \u001b[38;5;66;03m# add `call_defeased` since it is needed to convert yield to price, but it is not very common, and so Jesse suggests setting it to `True` to make this work (also because MSRB does not use it, and further downstream, we compare our converted prices to MSRB dollar prices)\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m converted_dollar_prices \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m row: \u001b[43mcompute_price\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)    \u001b[38;5;66;03m# using index 0 because the first item is the dollar price and the second item is the calc date\u001b[39;00m\n\u001b[1;32m     19\u001b[0m data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mficc_ytw\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m call_defeased_not_in_columns: data\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcall_defeased\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/ficc/ficc_python/ficc/pricing/price.py:122\u001b[0m, in \u001b[0;36mcompute_price\u001b[0;34m(trade, yield_rate)\u001b[0m\n\u001b[1;32m    120\u001b[0m frequency \u001b[38;5;241m=\u001b[39m get_frequency(trade\u001b[38;5;241m.\u001b[39minterest_payment_frequency)\n\u001b[1;32m    121\u001b[0m time_delta \u001b[38;5;241m=\u001b[39m get_time_delta_from_interest_frequency(frequency)\n\u001b[0;32m--> 122\u001b[0m my_prev_coupon_date, my_next_coupon_date \u001b[38;5;241m=\u001b[39m \u001b[43mget_prev_coupon_date_and_next_coupon_date\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrade\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime_delta\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    124\u001b[0m get_price_caller \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m end_date, redemption_value: get_price(trade\u001b[38;5;241m.\u001b[39mcusip, \n\u001b[1;32m    125\u001b[0m                                                                 my_prev_coupon_date, \n\u001b[1;32m    126\u001b[0m                                                                 trade\u001b[38;5;241m.\u001b[39mfirst_coupon_date, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    135\u001b[0m                                                                 time_delta, \n\u001b[1;32m    136\u001b[0m                                                                 trade\u001b[38;5;241m.\u001b[39mlast_period_accrues_from_date)\n\u001b[1;32m    138\u001b[0m called_redemption_type_is_1_or_5 \u001b[38;5;241m=\u001b[39m (\u001b[38;5;129;01mnot\u001b[39;00m pd\u001b[38;5;241m.\u001b[39misna(trade\u001b[38;5;241m.\u001b[39mcalled_redemption_type)) \u001b[38;5;129;01mand\u001b[39;00m (trade\u001b[38;5;241m.\u001b[39mcalled_redemption_type \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m1.0\u001b[39m, \u001b[38;5;241m5.0\u001b[39m))\n",
      "File \u001b[0;32m~/ficc/ficc_python/ficc/pricing/auxiliary_functions.py:72\u001b[0m, in \u001b[0;36mget_prev_coupon_date_and_next_coupon_date\u001b[0;34m(trade, frequency, time_delta)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m pd\u001b[38;5;241m.\u001b[39misnull(trade\u001b[38;5;241m.\u001b[39mnext_coupon_payment_date):\n\u001b[0;32m---> 72\u001b[0m         next_coupon_date \u001b[38;5;241m=\u001b[39m \u001b[43mget_next_coupon_date\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrade\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfirst_coupon_date\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrade\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msettlement_date\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime_delta\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     74\u001b[0m         next_coupon_date \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(trade\u001b[38;5;241m.\u001b[39mnext_coupon_payment_date)\n",
      "File \u001b[0;32m~/ficc/ficc_python/ficc/pricing/auxiliary_functions.py:39\u001b[0m, in \u001b[0;36mget_next_coupon_date\u001b[0;34m(first_coupon_date, start_date, time_delta)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m'''This function computes the next time a coupon is paid.\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;124;03mNote that this function could return a `next_coupon_date` that is after the end_date. \u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;124;03mThis does not create a problem since we deal with the final coupon separately in \u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;124;03m`next_coupon_date` is never null when there is a next coupon date. In the \u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;124;03mfuture, we should confirm whether this is the case.'''\u001b[39;00m\n\u001b[1;32m     38\u001b[0m date \u001b[38;5;241m=\u001b[39m first_coupon_date\n\u001b[0;32m---> 39\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[43mcompare_dates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_date\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     40\u001b[0m     date \u001b[38;5;241m=\u001b[39m date \u001b[38;5;241m+\u001b[39m time_delta\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m date\n",
      "File \u001b[0;32m~/ficc/ficc_python/ficc/utils/auxiliary_functions.py:104\u001b[0m, in \u001b[0;36mcompare_dates\u001b[0;34m(date1, date2)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompare_dates\u001b[39m(date1, date2):\n\u001b[1;32m    101\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''Compares two date objects whether they are in Timestamp or datetime.date. \u001b[39;00m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;124;03m    The different types are causing a future warning. If date1 occurs after date2, return 1. \u001b[39;00m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;124;03m    If date1 equals date2, return 0. Otherwise, return -1.'''\u001b[39;00m\n\u001b[0;32m--> 104\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[43mconvert_to_date\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdate1\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mconvert_to_date\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdate2\u001b[49m\u001b[43m)\u001b[49m)\u001b[38;5;241m.\u001b[39mtotal_seconds()\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'NaTType' and 'datetime.date'"
     ]
    }
   ],
   "source": [
    "new_data_yield_spreads = get_yield_spread_predictions(new_data, model_new_data)\n",
    "new_data['refund_price'] = 100\n",
    "new_data_dollar_prices = get_dollar_price_conversions(new_data, new_data_yield_spreads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply exclusions on bonds close to being called or maturing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "converted_dollar_price_column_name = 'ficc_dollar_price'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 741276 trades from old data for having 0 < days_to_call <= 400\n",
      "Removed 32272 trades from old data for having 0 < days_to_refund <= 400\n",
      "Removed 464858 trades from old data for having 0 < days_to_maturity <= 400\n",
      "Removed 1568 trades from old data for having days_to_maturity >= 30000\n"
     ]
    }
   ],
   "source": [
    "assert converted_dollar_price_column_name not in old_data.columns\n",
    "old_data[converted_dollar_price_column_name] = old_data_dollar_prices\n",
    "old_data_with_exclusions, _ = apply_exclusions(old_data, 'old data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert converted_dollar_price_column_name not in new_data.columns\n",
    "new_data[converted_dollar_price_column_name] = new_data_dollar_prices\n",
    "new_data_with_exclusions, _ = apply_exclusions(new_data, 'new data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot accuracy plots comparing the converted dollar price to the actual dollar price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "matplotlib is required for plotting when the default backend \"matplotlib\" is selected.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [31], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mold_data_with_exclusions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscatter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdollar_price\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconverted_dollar_price_column_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDarkBlue\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ficc/ficc_python/venv_py310/lib/python3.10/site-packages/pandas/plotting/_core.py:1697\u001b[0m, in \u001b[0;36mPlotAccessor.scatter\u001b[0;34m(self, x, y, s, c, **kwargs)\u001b[0m\n\u001b[1;32m   1614\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mscatter\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, y, s\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, c\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m PlotAccessor:\n\u001b[1;32m   1615\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1616\u001b[0m \u001b[38;5;124;03m    Create a scatter plot with varying marker point size and color.\u001b[39;00m\n\u001b[1;32m   1617\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1695\u001b[0m \u001b[38;5;124;03m        ...                       colormap='viridis')\u001b[39;00m\n\u001b[1;32m   1696\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1697\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkind\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mscatter\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ficc/ficc_python/venv_py310/lib/python3.10/site-packages/pandas/plotting/_core.py:920\u001b[0m, in \u001b[0;36mPlotAccessor.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    919\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 920\u001b[0m     plot_backend \u001b[38;5;241m=\u001b[39m \u001b[43m_get_plot_backend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbackend\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    922\u001b[0m     x, y, kind, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_call_args(\n\u001b[1;32m    923\u001b[0m         plot_backend\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parent, args, kwargs\n\u001b[1;32m    924\u001b[0m     )\n\u001b[1;32m    926\u001b[0m     kind \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_kind_aliases\u001b[38;5;241m.\u001b[39mget(kind, kind)\n",
      "File \u001b[0;32m~/ficc/ficc_python/venv_py310/lib/python3.10/site-packages/pandas/plotting/_core.py:1886\u001b[0m, in \u001b[0;36m_get_plot_backend\u001b[0;34m(backend)\u001b[0m\n\u001b[1;32m   1883\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backend_str \u001b[38;5;129;01min\u001b[39;00m _backends:\n\u001b[1;32m   1884\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _backends[backend_str]\n\u001b[0;32m-> 1886\u001b[0m module \u001b[38;5;241m=\u001b[39m \u001b[43m_load_backend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbackend_str\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1887\u001b[0m _backends[backend_str] \u001b[38;5;241m=\u001b[39m module\n\u001b[1;32m   1888\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\n",
      "File \u001b[0;32m~/ficc/ficc_python/venv_py310/lib/python3.10/site-packages/pandas/plotting/_core.py:1817\u001b[0m, in \u001b[0;36m_load_backend\u001b[0;34m(backend)\u001b[0m\n\u001b[1;32m   1815\u001b[0m         module \u001b[38;5;241m=\u001b[39m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpandas.plotting._matplotlib\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1816\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[0;32m-> 1817\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[1;32m   1818\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmatplotlib is required for plotting when the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1819\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdefault backend \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmatplotlib\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is selected.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   1820\u001b[0m         ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1821\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m module\n\u001b[1;32m   1823\u001b[0m found_backend \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: matplotlib is required for plotting when the default backend \"matplotlib\" is selected."
     ]
    }
   ],
   "source": [
    "old_data_with_exclusions.plot.scatter(x='dollar_price', y=converted_dollar_price_column_name, c='DarkBlue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of errors: 523438521.138\n",
      "Mean of errors: 101.0526972343059\n"
     ]
    }
   ],
   "source": [
    "old_data_with_exclusions_price_delta = abs(old_data_with_exclusions[converted_dollar_price_column_name] - old_data_with_exclusions['dollar_price'])\n",
    "print(f'Sum of errors: {np.sum(old_data_with_exclusions_price_delta)}')\n",
    "print(f'Mean of errors: {np.mean(old_data_with_exclusions_price_delta)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data_with_exclusions.plot.scatter(x='dollar_price', y=converted_dollar_price_column_name, c='DarkBlue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data_with_exclusions_price_delta = abs(new_data_with_exclusions[converted_dollar_price_column_name] - new_data_with_exclusions['dollar_price'])\n",
    "print(f'Sum of errors: {np.sum(new_data_with_exclusions_price_delta)}')\n",
    "print(f'Mean of errors: {np.mean(new_data_with_exclusions_price_delta)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
