{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare Datasets\n",
    "\n",
    "Created by Mitas Ray on 2024-11-19.\n",
    "\n",
    "This notebook is used to compare two datasets. The procedure is to \n",
    "1. restrict the datasets to the same datetime window\n",
    "2. perform high-level analysis on the values in the dataset\n",
    "3. train a model with these datasets and see similar accuracy results\n",
    "\n",
    "To run the notebook,\n",
    "- on linux: use `ficc_python/requirements_py310.txt`, and use `>>> pip install jupyter`\n",
    "- on mac: use `ficc_python/requirements_py310_mac_jupyter.txt`\n",
    "\n",
    "Change the following files to enable credentials and the correct working directory:\n",
    "- `automated_training_auxiliary_functions.py::get_creds(...)`\n",
    "- `ficc/app_engine/demo/server/modules/get_creds.py::get_creds(...)`\n",
    "- `automated_training_auxiliary_variables.py::WORKING_DIRECTORY`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loads the autoreload extension\n",
    "%load_ext autoreload\n",
    "# automatically reloads all imported modules when their source code changes\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 5 workers.\n",
      "INFO: Pandarallel will use standard multiprocessing data transfer (pipe) to transfer data between the main process and workers.\n",
      "Initialized pandarallel with 5 cores\n",
      "INFO: Pandarallel will run on 5 workers.\n",
      "INFO: Pandarallel will use standard multiprocessing data transfer (pipe) to transfer data between the main process and workers.\n",
      "Initialized pandarallel with 5 cores\n",
      "INFO: Pandarallel will run on 5 workers.\n",
      "INFO: Pandarallel will use standard multiprocessing data transfer (pipe) to transfer data between the main process and workers.\n",
      "Initialized pandarallel with 5 cores\n",
      "In PRODUCTION mode (to change to TESTING mode, set `TESTING` to `True`); all files and models will be saved and NUM_EPOCHS=100\n",
      "INFO: Pandarallel will run on 5 workers.\n",
      "INFO: Pandarallel will use standard multiprocessing data transfer (pipe) to transfer data between the main process and workers.\n",
      "Initialized pandarallel with 5 cores\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# importing from parent directory: https://stackoverflow.com/questions/714063/importing-modules-from-parent-folder\n",
    "import sys\n",
    "sys.path.insert(0,'../')\n",
    "\n",
    "\n",
    "from ficc.utils.auxiliary_functions import get_ys_trade_history_features\n",
    "from ficc.utils.gcp_storage_functions import download_data\n",
    "\n",
    "from automated_training_auxiliary_variables import CATEGORICAL_FEATURES, BINARY, NON_CAT_FEATURES, NUM_TRADES_IN_HISTORY_YIELD_SPREAD_MODEL, BUCKET_NAME, MODEL_TO_CUMULATIVE_DATA_PICKLE_FILENAME, WORKING_DIRECTORY\n",
    "from automated_training_auxiliary_functions import STORAGE_CLIENT, MODEL_NAME_TO_KERAS_MODEL, check_that_model_is_supported, fit_encoders, create_input, train_and_evaluate_model, create_summary_of_results, get_optional_arguments_for_process_data, save_model\n",
    "from set_random_seed import set_seed\n",
    "\n",
    "\n",
    "set_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working directory: /Users/mitas/ficc/ficc_python. If this is incorrect, change it in `automated_training_auxiliary_variables.py::WORKING_DIRECTORY\n"
     ]
    }
   ],
   "source": [
    "print(f'Working directory: {WORKING_DIRECTORY}. If this is incorrect, change it in `automated_training_auxiliary_variables.py::WORKING_DIRECTORY`')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = 'yield_spread_with_similar_trades'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restrict the data between a start and end datetime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_to_datetime(datetime_as_string: datetime | str) -> datetime:\n",
    "    if isinstance(datetime_as_string, datetime): return datetime_as_string\n",
    "    string_format = '%Y-%m-%d %H:%M:%S'\n",
    "    try:\n",
    "        return datetime.strptime(datetime_as_string, string_format)\n",
    "    except Exception as e:\n",
    "        print(f'{datetime_as_string} must be in {string_format} format')\n",
    "        raise e\n",
    "\n",
    "\n",
    "def restrict_data_to_specified_time_window(data: pd.DataFrame, \n",
    "                                           datetime_column_name: str, \n",
    "                                           start_datetime: datetime | str, \n",
    "                                           end_datetime: datetime | str) -> pd.DataFrame:\n",
    "    '''Return a truncated version of `data` with values of `datetime_column_name` between \n",
    "    `start_datetime` and `end_datetime`.'''\n",
    "    start_datetime, end_datetime = string_to_datetime(start_datetime), string_to_datetime(end_datetime)\n",
    "    after_start_datetime = data[datetime_column_name] >= start_datetime\n",
    "    before_end_datetime = data[datetime_column_name] <= end_datetime\n",
    "    rows_to_keep = after_start_datetime & before_end_datetime\n",
    "    rows_remaining = rows_to_keep.sum()\n",
    "    print(f'{len(data) - rows_remaining} rows removed from the original {len(data)} rows. {rows_remaining} rows remain.')\n",
    "    return data[rows_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "may_1_start_of_day = '2024-05-01 00:00:00'\n",
    "october_1_start_of_day = '2024-10-01 00:00:00'\n",
    "october_31_end_of_day = '2024-10-31 23:59:59'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def restrict_data_on_trade_datetime(data: pd.DataFrame, start_datetime_as_string: str, end_datetime_as_string: str) -> pd.DataFrame:\n",
    "    return restrict_data_to_specified_time_window(data, 'trade_datetime', start_datetime_as_string, end_datetime_as_string)\n",
    "\n",
    "\n",
    "def restrict_data_to_october_on_trade_datetime(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    return restrict_data_on_trade_datetime(data, october_1_start_of_day, october_31_end_of_day)\n",
    "\n",
    "\n",
    "def restrict_data_from_may_to_october_on_trade_datetime(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    return restrict_data_on_trade_datetime(data, may_1_start_of_day, october_31_end_of_day)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get data from Google Cloud Storage (or locally saved files) and restrict to desired dates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILES_DIRECTORY = f'{WORKING_DIRECTORY}/files'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_data_file_path = f'{FILES_DIRECTORY}/old_data.pkl'\n",
    "if os.path.isfile(old_data_file_path):\n",
    "    old_data = pd.read_pickle(old_data_file_path)\n",
    "else:\n",
    "    old_data = download_data(STORAGE_CLIENT, BUCKET_NAME, MODEL_TO_CUMULATIVE_DATA_PICKLE_FILENAME[MODEL])\n",
    "    old_data.to_pickle(old_data_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 rows removed from the original 6419831 rows. 6419831 rows remain.\n"
     ]
    }
   ],
   "source": [
    "old_data = restrict_data_from_may_to_october_on_trade_datetime(old_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_files_from_sp_data_for_modeling_bucket(file_names: list) -> pd.DataFrame:\n",
    "    '''Download each file in `file_names` and concatenate the dataframes together.'''\n",
    "    return pd.concat([download_data(STORAGE_CLIENT, 'sp_data_for_modeling', file_name) for file_name in file_names])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data_file_path = f'{FILES_DIRECTORY}/new_data.pkl'\n",
    "if os.path.isfile(new_data_file_path):\n",
    "    new_data = pd.read_pickle(new_data_file_path)\n",
    "else:\n",
    "    new_data = download_files_from_sp_data_for_modeling_bucket(['trades_2024-05-01_to_2024-05-31.pkl', \n",
    "                                                                'trades_2024-06-01_to_2024-06-30.pkl', \n",
    "                                                                'trades_2024-07-01_to_2024-07-31.pkl', \n",
    "                                                                'trades_2024-08-01_to_2024-08-31.pkl', \n",
    "                                                                'trades_2024-09-01_to_2024-09-30.pkl', \n",
    "                                                                'trades_2024-10-01_to_2024-10-31.pkl'])\n",
    "    new_data.to_pickle(new_data_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 rows removed from the original 6463891 rows. 6463891 rows remain.\n"
     ]
    }
   ],
   "source": [
    "new_data = restrict_data_from_may_to_october_on_trade_datetime(new_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_shapes(df1: pd.DataFrame, df2: pd.DataFrame) -> None:\n",
    "    print('\\n=== Dataset Shapes ===')\n",
    "    print(f'Dataset 1 Shape: {df1.shape}')\n",
    "    print(f'Dataset 2 Shape: {df2.shape}')\n",
    "    num_rows_df1, num_rows_df2 = df1.shape[0], df2.shape[0]\n",
    "    num_rows_difference = num_rows_df1 - num_rows_df2\n",
    "    if num_rows_difference == 0:\n",
    "        print('Both datasets have the same number of rows')\n",
    "    elif num_rows_difference > 0:\n",
    "        print(f'Dataset 1 has {num_rows_difference} ({round(num_rows_difference / num_rows_df2 * 100, 3)}%) more rows than Dataset 2')\n",
    "    elif num_rows_difference < 0:\n",
    "        print(f'Dataset 2 has {abs(num_rows_difference)} ({round(abs(num_rows_difference) / num_rows_df1 * 100, 3)}%) more rows than Dataset 1')\n",
    "    else:\n",
    "        raise ValueError(f'{num_rows_difference} has a value that cannot be compared to 0')\n",
    "\n",
    "\n",
    "def compare_columns(df1: pd.DataFrame, df2: pd.DataFrame) -> None:\n",
    "    print('\\n=== Column Comparison ===')\n",
    "    print(f'Dataset 1 Columns: {df1.columns.tolist()}')\n",
    "    print(f'Dataset 2 Columns: {df2.columns.tolist()}')\n",
    "\n",
    "    print('\\n=== Common and Unique Columns ===')\n",
    "    common_cols = set(df1.columns).intersection(set(df2.columns))\n",
    "    unique_to_df1 = set(df1.columns) - set(df2.columns)\n",
    "    unique_to_df2 = set(df2.columns) - set(df1.columns)\n",
    "    print(f'Common Columns: {common_cols}')\n",
    "    print(f'Columns only in Dataset 1: {unique_to_df1}')\n",
    "    print(f'Columns only in Dataset 2: {unique_to_df2}')\n",
    "\n",
    "\n",
    "def compare_data_types(df1: pd.DataFrame, df2: pd.DataFrame) -> None:\n",
    "    print('\\n=== Data Types ===')\n",
    "    print('Dataset 1 Data Types:')\n",
    "    print(df1.dtypes)\n",
    "    print('\\nDataset 2 Data Types:')\n",
    "    print(df2.dtypes)\n",
    "\n",
    "    ## below code does not work if there is a column with dtype numpy array\n",
    "    # print('\\n=== Unique Values per Column ===')\n",
    "    # print('Dataset 1 Unique Values:')\n",
    "    # print(df1.nunique())\n",
    "    # print('\\nDataset 2 Unique Values:')\n",
    "    # print(df2.nunique())\n",
    "\n",
    "\n",
    "def missing_values(df1: pd.DataFrame, df2: pd.DataFrame) -> None:\n",
    "    print('\\n=== Missing Values ===')\n",
    "    print('Dataset 1 Missing Values:')\n",
    "    missing_df1 = df1.isnull().sum()\n",
    "    print(missing_df1[missing_df1 > 0])\n",
    "    \n",
    "    print('\\nDataset 2 Missing Values:')\n",
    "    missing_df2 = df2.isnull().sum()\n",
    "    print(missing_df2[missing_df2 > 0])\n",
    "\n",
    "\n",
    "def check_last_trade_in_history(df1: pd.DataFrame, df2: pd.DataFrame) -> None:\n",
    "    print('\\n=== Last Trade in History ===')\n",
    "    columns_to_check = ['last_rtrs_control_number']\n",
    "    column_to_merge_on = 'rtrs_control_number'\n",
    "    columns_to_keep = [column_to_merge_on] + columns_to_check\n",
    "    assert all([((column in df1.columns) and (column in df2.columns)) for column in columns_to_keep]), f'Not all columns in {columns_to_keep} are present in both datasets'\n",
    "    df1, df2 = df1[columns_to_keep], df2[columns_to_keep]\n",
    "    suffix1, suffix2 = '_df1', '_df2'\n",
    "    merged_df = pd.merge(df1, df2, on=column_to_merge_on, suffixes=(suffix1, suffix2))\n",
    "    for column in columns_to_check:\n",
    "        col1, col2 = merged_df[column + suffix1], merged_df[column + suffix2]\n",
    "        differences = ~((col1.isna() & col2.isna()) | (col1 == col2))\n",
    "        print(f'{column}: {differences.sum()} rows have different values for the same {column_to_merge_on}')\n",
    "\n",
    "\n",
    "def statistical_summary(df1: pd.DataFrame, df2: pd.DataFrame) -> None:\n",
    "    '''`.describe(...)` has issues if there is a column with dtype numpy array.'''\n",
    "    print('\\n=== Statistical Summary ===')\n",
    "    print('Dataset 1 Summary:')\n",
    "    print(df1.describe(include='all'))\n",
    "    print('\\nDataset 2 Summary:')\n",
    "    print(df2.describe(include='all'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Dataset Shapes ===\n",
      "Dataset 1 Shape: (6419831, 141)\n",
      "Dataset 2 Shape: (6463891, 139)\n",
      "Dataset 2 has 44060 (0.686%) more rows than Dataset 1\n",
      "\n",
      "=== Column Comparison ===\n",
      "Dataset 1 Columns: ['rtrs_control_number', 'cusip', 'yield', 'is_callable', 'refund_date', 'accrual_date', 'dated_date', 'next_sink_date', 'coupon', 'delivery_date', 'trade_date', 'trade_datetime', 'par_call_date', 'interest_payment_frequency', 'is_called', 'is_non_transaction_based_compensation', 'is_general_obligation', 'callable_at_cav', 'extraordinary_make_whole_call', 'make_whole_call', 'has_unexpired_lines_of_credit', 'escrow_exists', 'incorporated_state_code', 'trade_type', 'par_traded', 'maturity_date', 'settlement_date', 'next_call_date', 'issue_amount', 'maturity_amount', 'issue_price', 'orig_principal_amount', 'max_amount_outstanding', 'dollar_price', 'calc_date', 'purpose_sub_class', 'called_redemption_type', 'calc_day_cat', 'previous_coupon_payment_date', 'instrument_primary_name', 'purpose_class', 'call_timing', 'call_timing_in_part', 'sink_frequency', 'sink_amount_type', 'issue_text', 'state_tax_status', 'series_name', 'transaction_type', 'next_call_price', 'par_call_price', 'when_issued', 'min_amount_outstanding', 'original_yield', 'par_price', 'default_indicator', 'sp_stand_alone', 'sp_long', 'moodys_long', 'coupon_type', 'federal_tax_status', 'use_of_proceeds', 'muni_security_type', 'muni_issue_type', 'capital_type', 'other_enhancement_type', 'next_coupon_payment_date', 'first_coupon_date', 'last_period_accrues_from_date', 'rating', 'trade_history', 'last_yield_spread', 'last_ficc_ycl', 'last_rtrs_control_number', 'last_yield', 'last_dollar_price', 'last_seconds_ago', 'last_size', 'last_calc_date', 'last_maturity_date', 'last_next_call_date', 'last_par_call_date', 'last_refund_date', 'last_trade_datetime', 'last_calc_day_cat', 'last_settlement_date', 'last_trade_type', 'similar_trade_history', 'ficc_ycl', 'yield_spread', 'treasury_rate', 'ficc_treasury_spread', 'quantity', 'callable', 'called', 'zerocoupon', 'whenissued', 'sinking', 'deferred', 'days_to_settle', 'days_to_maturity', 'days_to_call', 'days_to_refund', 'days_to_par', 'call_to_maturity', 'accrued_days', 'days_in_interest_payment', 'scaled_accrued_days', 'A/E', 'last_trade_date', 'new_ficc_ycl', 'target_attention_features', 'new_ys', 'max_ys_ys', 'max_ys_ttypes', 'max_ys_ago', 'max_ys_qdiff', 'min_ys_ys', 'min_ys_ttypes', 'min_ys_ago', 'min_ys_qdiff', 'max_qty_ys', 'max_qty_ttypes', 'max_qty_ago', 'max_qty_qdiff', 'min_ago_ys', 'min_ago_ttypes', 'min_ago_ago', 'min_ago_qdiff', 'D_min_ago_ys', 'D_min_ago_ttypes', 'D_min_ago_ago', 'D_min_ago_qdiff', 'P_min_ago_ys', 'P_min_ago_ttypes', 'P_min_ago_ago', 'P_min_ago_qdiff', 'S_min_ago_ys', 'S_min_ago_ttypes', 'S_min_ago_ago', 'S_min_ago_qdiff']\n",
      "Dataset 2 Columns: ['rtrs_control_number', 'cusip', 'yield', 'is_callable', 'refund_date', 'accrual_date', 'dated_date', 'next_sink_date', 'coupon', 'delivery_date', 'trade_date', 'trade_datetime', 'par_call_date', 'interest_payment_frequency', 'is_called', 'is_non_transaction_based_compensation', 'is_general_obligation', 'callable_at_cav', 'extraordinary_make_whole_call', 'make_whole_call', 'has_unexpired_lines_of_credit', 'escrow_exists', 'incorporated_state_code', 'trade_type', 'par_traded', 'maturity_date', 'settlement_date', 'next_call_date', 'issue_amount', 'maturity_amount', 'issue_price', 'orig_principal_amount', 'max_amount_outstanding', 'dollar_price', 'calc_date', 'purpose_sub_class', 'called_redemption_type', 'calc_day_cat', 'previous_coupon_payment_date', 'instrument_primary_name', 'purpose_class', 'call_timing', 'call_timing_in_part', 'sink_frequency', 'sink_amount_type', 'issue_text', 'state_tax_status', 'series_name', 'transaction_type', 'next_call_price', 'par_call_price', 'when_issued', 'min_amount_outstanding', 'original_yield', 'par_price', 'default_indicator', 'sp_long', 'coupon_type', 'federal_tax_status', 'use_of_proceeds', 'muni_security_type', 'muni_issue_type', 'capital_type', 'other_enhancement_type', 'next_coupon_payment_date', 'first_coupon_date', 'last_period_accrues_from_date', 'rating', 'trade_history', 'last_yield_spread', 'last_ficc_ycl', 'last_rtrs_control_number', 'last_yield', 'last_dollar_price', 'last_seconds_ago', 'last_size', 'last_calc_date', 'last_maturity_date', 'last_next_call_date', 'last_par_call_date', 'last_refund_date', 'last_trade_datetime', 'last_calc_day_cat', 'last_settlement_date', 'last_trade_type', 'similar_trade_history', 'ficc_ycl', 'yield_spread', 'treasury_rate', 'ficc_treasury_spread', 'quantity', 'callable', 'called', 'zerocoupon', 'whenissued', 'sinking', 'deferred', 'days_to_settle', 'days_to_maturity', 'days_to_call', 'days_to_refund', 'days_to_par', 'call_to_maturity', 'accrued_days', 'days_in_interest_payment', 'scaled_accrued_days', 'A/E', 'last_trade_date', 'new_ficc_ycl', 'target_attention_features', 'new_ys', 'max_ys_ys', 'max_ys_ttypes', 'max_ys_ago', 'max_ys_qdiff', 'min_ys_ys', 'min_ys_ttypes', 'min_ys_ago', 'min_ys_qdiff', 'max_qty_ys', 'max_qty_ttypes', 'max_qty_ago', 'max_qty_qdiff', 'min_ago_ys', 'min_ago_ttypes', 'min_ago_ago', 'min_ago_qdiff', 'D_min_ago_ys', 'D_min_ago_ttypes', 'D_min_ago_ago', 'D_min_ago_qdiff', 'P_min_ago_ys', 'P_min_ago_ttypes', 'P_min_ago_ago', 'P_min_ago_qdiff', 'S_min_ago_ys', 'S_min_ago_ttypes', 'S_min_ago_ago', 'S_min_ago_qdiff']\n",
      "\n",
      "=== Common and Unique Columns ===\n",
      "Common Columns: {'S_min_ago_ys', 'muni_issue_type', 'purpose_class', 'last_par_call_date', 'previous_coupon_payment_date', 'last_settlement_date', 'min_ago_qdiff', 'call_timing', 'last_trade_type', 'rtrs_control_number', 'original_yield', 'state_tax_status', 'sinking', 'last_yield', 'dollar_price', 'last_dollar_price', 'cusip', 'issue_amount', 'par_traded', 'deferred', 'min_ago_ago', 'called', 'capital_type', 'last_size', 'call_to_maturity', 'purpose_sub_class', 'S_min_ago_ago', 'max_qty_ys', 'target_attention_features', 'days_to_settle', 'trade_type', 'interest_payment_frequency', 'last_seconds_ago', 'days_to_refund', 'yield', 'dated_date', 'refund_date', 'min_amount_outstanding', 'min_ago_ys', 'last_ficc_ycl', 'min_ys_qdiff', 'coupon_type', 'P_min_ago_ttypes', 'new_ys', 'last_calc_date', 'is_non_transaction_based_compensation', 'is_callable', 'P_min_ago_ys', 'muni_security_type', 'rating', 'scaled_accrued_days', 'settlement_date', 'issue_price', 'is_general_obligation', 'last_refund_date', 'new_ficc_ycl', 'next_coupon_payment_date', 'next_call_price', 'max_ys_ttypes', 'sink_frequency', 'days_to_maturity', 'callable_at_cav', 'treasury_rate', 'trade_date', 'when_issued', 'ficc_ycl', 'D_min_ago_ago', 'calc_date', 'max_ys_ago', 'max_amount_outstanding', 'calc_day_cat', 'call_timing_in_part', 'transaction_type', 'quantity', 'P_min_ago_qdiff', 'escrow_exists', 'ficc_treasury_spread', 'extraordinary_make_whole_call', 'max_ys_ys', 'sink_amount_type', 'issue_text', 'min_ago_ttypes', 'next_sink_date', 'first_coupon_date', 'max_ys_qdiff', 'min_ys_ys', 'S_min_ago_qdiff', 'par_call_date', 'P_min_ago_ago', 'D_min_ago_ys', 'next_call_date', 'trade_history', 'accrued_days', 'min_ys_ttypes', 'default_indicator', 'par_call_price', 'par_price', 'series_name', 'last_next_call_date', 'accrual_date', 'has_unexpired_lines_of_credit', 'D_min_ago_qdiff', 'is_called', 'delivery_date', 'federal_tax_status', 'yield_spread', 'A/E', 'maturity_date', 'orig_principal_amount', 'instrument_primary_name', 'days_to_par', 'zerocoupon', 'D_min_ago_ttypes', 'min_ys_ago', 'whenissued', 'last_trade_date', 'callable', 'trade_datetime', 'incorporated_state_code', 'sp_long', 'days_in_interest_payment', 'maturity_amount', 'use_of_proceeds', 'last_rtrs_control_number', 'last_calc_day_cat', 'other_enhancement_type', 'similar_trade_history', 'last_yield_spread', 'coupon', 'last_maturity_date', 'last_trade_datetime', 'S_min_ago_ttypes', 'called_redemption_type', 'max_qty_ago', 'max_qty_qdiff', 'last_period_accrues_from_date', 'days_to_call', 'make_whole_call', 'max_qty_ttypes'}\n",
      "Columns only in Dataset 1: {'moodys_long', 'sp_stand_alone'}\n",
      "Columns only in Dataset 2: set()\n",
      "\n",
      "=== Missing Values ===\n",
      "Dataset 1 Missing Values:\n",
      "refund_date                      6178845\n",
      "next_sink_date                   5071097\n",
      "par_call_date                    2101210\n",
      "next_call_date                   2097316\n",
      "purpose_sub_class                1360240\n",
      "previous_coupon_payment_date      951110\n",
      "instrument_primary_name              284\n",
      "original_yield                      7187\n",
      "moodys_long                      1771008\n",
      "use_of_proceeds                       30\n",
      "muni_issue_type                  6152731\n",
      "other_enhancement_type           5524583\n",
      "next_coupon_payment_date              10\n",
      "first_coupon_date                      1\n",
      "last_period_accrues_from_date      87720\n",
      "last_ficc_ycl                     157589\n",
      "last_rtrs_control_number          157589\n",
      "last_yield                        157589\n",
      "last_size                         157589\n",
      "last_calc_date                    157589\n",
      "last_maturity_date                157589\n",
      "last_next_call_date              2188720\n",
      "last_par_call_date               2192293\n",
      "last_refund_date                 6187579\n",
      "last_trade_datetime               157589\n",
      "last_calc_day_cat                 157589\n",
      "last_settlement_date              157589\n",
      "last_trade_type                   157589\n",
      "last_trade_date                   157589\n",
      "dtype: int64\n",
      "\n",
      "Dataset 2 Missing Values:\n",
      "refund_date                      6244078\n",
      "next_sink_date                   5120737\n",
      "delivery_date                         75\n",
      "par_call_date                    2106888\n",
      "next_call_date                   2098456\n",
      "purpose_sub_class                 737874\n",
      "previous_coupon_payment_date      842108\n",
      "instrument_primary_name              126\n",
      "original_yield                     12916\n",
      "use_of_proceeds                        8\n",
      "muni_issue_type                  6324354\n",
      "other_enhancement_type           5942843\n",
      "next_coupon_payment_date          319947\n",
      "first_coupon_date                     31\n",
      "last_period_accrues_from_date      97437\n",
      "last_ficc_ycl                     178028\n",
      "last_rtrs_control_number          178028\n",
      "last_yield                        178028\n",
      "last_size                         178028\n",
      "last_calc_date                    178028\n",
      "last_maturity_date                178028\n",
      "last_next_call_date              2216371\n",
      "last_par_call_date               2220026\n",
      "last_refund_date                 6231574\n",
      "last_trade_datetime               178028\n",
      "last_calc_day_cat                 178028\n",
      "last_settlement_date              178028\n",
      "last_trade_type                   178028\n",
      "last_trade_date                   178028\n",
      "dtype: int64\n",
      "\n",
      "=== Last Trade in History ===\n",
      "last_rtrs_control_number: 6739 rows have different values for the same rtrs_control_number\n"
     ]
    }
   ],
   "source": [
    "compare_shapes(old_data, new_data)\n",
    "compare_columns(old_data, new_data)\n",
    "# compare_data_types(old_data, new_data)\n",
    "missing_values(old_data, new_data)\n",
    "check_last_trade_in_history(old_data, new_data)\n",
    "# statistical_summary(old_data, new_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train yield spread with similar trades model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_features_for_each_trade_in_history() -> int:\n",
    "    optional_arguments_for_process_data = get_optional_arguments_for_process_data(MODEL)\n",
    "    use_treasury_spread = optional_arguments_for_process_data.get('use_treasury_spread', False)\n",
    "    trade_history_features = get_ys_trade_history_features(use_treasury_spread)\n",
    "    return len(trade_history_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(data: pd.DataFrame, \n",
    "                last_trade_date_for_training_dataset: str, \n",
    "                model_name_suffix: str = ''):\n",
    "    '''Heavily inspired by `automated_trianing_auxiliary_functions::train_model(...)`. The main changes are: \n",
    "    (1) assume that we are using the yield spread with similar trades model,\n",
    "    (2) do not have an exclusions function\n",
    "    (3) do not restrict the test set to just a single day\n",
    "    '''\n",
    "    check_that_model_is_supported(MODEL)\n",
    "    encoders, fmax = fit_encoders(data, CATEGORICAL_FEATURES, MODEL)\n",
    "    test_data = data[data.trade_date > last_trade_date_for_training_dataset]    # `test_data` can only contain trades after `last_trade_date_for_training_dataset`\n",
    "    train_data = data[data.trade_date <= last_trade_date_for_training_dataset]    # `train_data` only contains trades before and including `last_trade_date_for_training_dataset`\n",
    "    training_set_info = f'Training set contains {len(train_data)} trades ranging from trade datetimes of {train_data.trade_datetime.min()} to {train_data.trade_datetime.max()}'\n",
    "    test_set_info = f'Test set contains {len(test_data)} trades ranging from trade datetimes of {test_data.trade_datetime.min()} to {test_data.trade_datetime.max()}'\n",
    "    print(training_set_info)\n",
    "    print(test_set_info)\n",
    "\n",
    "    x_train, y_train = create_input(train_data, encoders, MODEL)\n",
    "    x_test, y_test = create_input(test_data, encoders, MODEL)\n",
    "\n",
    "    keras_model = MODEL_NAME_TO_KERAS_MODEL[MODEL]\n",
    "    untrained_model = keras_model(x_train, \n",
    "                                  NUM_TRADES_IN_HISTORY_YIELD_SPREAD_MODEL, \n",
    "                                  get_num_features_for_each_trade_in_history(), \n",
    "                                  CATEGORICAL_FEATURES, \n",
    "                                  NON_CAT_FEATURES, \n",
    "                                  BINARY, \n",
    "                                  fmax)\n",
    "    trained_model, mae, history = train_and_evaluate_model(untrained_model, x_train, y_train, x_test, y_test)\n",
    "    result_df = create_summary_of_results(trained_model, test_data, x_test, y_test)\n",
    "    save_model(trained_model, None, MODEL, model_name_suffix, upload_to_google_cloud_bucket=False)    # setting `encoders=None` to not save the encoders file\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set contains 5257795 trades ranging from trade datetimes of 2024-05-01 07:01:05 to 2024-09-30 18:24:32\n",
      "Test set contains 1162036 trades ranging from trade datetimes of 2024-10-01 00:00:00 to 2024-10-31 18:35:10\n",
      "BEGIN create_input\n",
      "END create_input. Execution time: 0:00:32.438\n",
      "BEGIN create_input\n",
      "END create_input. Execution time: 0:00:07.218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-19 15:13:43.898232: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:693] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"CPU\" model: \"0\" frequency: 2400 num_cores: 10 environment { key: \"cpu_instruction_set\" value: \"ARM NEON\" } environment { key: \"eigen\" value: \"3.4.90\" } l1_cache_size: 16384 l2_cache_size: 524288 l3_cache_size: 524288 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4732/4733 [============================>.] - ETA: 0s - loss: 33.2542 - mean_absolute_error: 33.2542"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-19 15:18:21.142926: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:693] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"CPU\" model: \"0\" frequency: 2400 num_cores: 10 environment { key: \"cpu_instruction_set\" value: \"ARM NEON\" } environment { key: \"eigen\" value: \"3.4.90\" } l1_cache_size: 16384 l2_cache_size: 524288 l3_cache_size: 524288 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4733/4733 [==============================] - 294s 61ms/step - loss: 33.2542 - mean_absolute_error: 33.2542 - val_loss: 15.0574 - val_mean_absolute_error: 15.0574\n",
      "Epoch 2/100\n",
      "4733/4733 [==============================] - 284s 60ms/step - loss: 14.8060 - mean_absolute_error: 14.8060 - val_loss: 13.7381 - val_mean_absolute_error: 13.7381\n",
      "Epoch 3/100\n",
      "4733/4733 [==============================] - 292s 62ms/step - loss: 13.9289 - mean_absolute_error: 13.9289 - val_loss: 14.1743 - val_mean_absolute_error: 14.1743\n",
      "Epoch 4/100\n",
      "4733/4733 [==============================] - 293s 62ms/step - loss: 13.6047 - mean_absolute_error: 13.6047 - val_loss: 13.8678 - val_mean_absolute_error: 13.8678\n",
      "Epoch 5/100\n",
      "4733/4733 [==============================] - 287s 61ms/step - loss: 13.3866 - mean_absolute_error: 13.3866 - val_loss: 13.0431 - val_mean_absolute_error: 13.0431\n",
      "Epoch 6/100\n",
      "4733/4733 [==============================] - 294s 62ms/step - loss: 13.2207 - mean_absolute_error: 13.2207 - val_loss: 12.6479 - val_mean_absolute_error: 12.6479\n",
      "Epoch 7/100\n",
      "4733/4733 [==============================] - 288s 61ms/step - loss: 13.0887 - mean_absolute_error: 13.0887 - val_loss: 13.0289 - val_mean_absolute_error: 13.0289\n",
      "Epoch 8/100\n",
      "4733/4733 [==============================] - 284s 60ms/step - loss: 12.9717 - mean_absolute_error: 12.9717 - val_loss: 13.0576 - val_mean_absolute_error: 13.0576\n",
      "Epoch 9/100\n",
      "4733/4733 [==============================] - 280s 59ms/step - loss: 12.8834 - mean_absolute_error: 12.8834 - val_loss: 13.1663 - val_mean_absolute_error: 13.1663\n",
      "Epoch 10/100\n",
      "4733/4733 [==============================] - 283s 60ms/step - loss: 12.7965 - mean_absolute_error: 12.7965 - val_loss: 12.9449 - val_mean_absolute_error: 12.9449\n",
      "Epoch 11/100\n",
      "4733/4733 [==============================] - 282s 60ms/step - loss: 12.7245 - mean_absolute_error: 12.7245 - val_loss: 12.7549 - val_mean_absolute_error: 12.7549\n",
      "Epoch 12/100\n",
      "4733/4733 [==============================] - 287s 61ms/step - loss: 12.6605 - mean_absolute_error: 12.6605 - val_loss: 12.7472 - val_mean_absolute_error: 12.7472\n",
      "Epoch 13/100\n",
      "4733/4733 [==============================] - 282s 60ms/step - loss: 12.5841 - mean_absolute_error: 12.5841 - val_loss: 13.1207 - val_mean_absolute_error: 13.1207\n",
      "Epoch 14/100\n",
      "4733/4733 [==============================] - 285s 60ms/step - loss: 12.5326 - mean_absolute_error: 12.5326 - val_loss: 12.7423 - val_mean_absolute_error: 12.7423\n",
      "Epoch 15/100\n",
      "4733/4733 [==============================] - 281s 59ms/step - loss: 12.4739 - mean_absolute_error: 12.4739 - val_loss: 12.9309 - val_mean_absolute_error: 12.9309\n",
      "Epoch 16/100\n",
      "4733/4733 [==============================] - 282s 60ms/step - loss: 12.4233 - mean_absolute_error: 12.4233 - val_loss: 12.3537 - val_mean_absolute_error: 12.3537\n",
      "Epoch 17/100\n",
      "4733/4733 [==============================] - 283s 60ms/step - loss: 12.3760 - mean_absolute_error: 12.3760 - val_loss: 12.6237 - val_mean_absolute_error: 12.6237\n",
      "Epoch 18/100\n",
      "4733/4733 [==============================] - 285s 60ms/step - loss: 12.3301 - mean_absolute_error: 12.3301 - val_loss: 12.7318 - val_mean_absolute_error: 12.7318\n",
      "Epoch 19/100\n",
      "4733/4733 [==============================] - 281s 59ms/step - loss: 12.2888 - mean_absolute_error: 12.2888 - val_loss: 12.8758 - val_mean_absolute_error: 12.8758\n",
      "Epoch 20/100\n",
      "4733/4733 [==============================] - 287s 61ms/step - loss: 12.2420 - mean_absolute_error: 12.2420 - val_loss: 12.7800 - val_mean_absolute_error: 12.7800\n",
      "Epoch 21/100\n",
      "4733/4733 [==============================] - 283s 60ms/step - loss: 12.2163 - mean_absolute_error: 12.2163 - val_loss: 12.6317 - val_mean_absolute_error: 12.6317\n",
      "Epoch 22/100\n",
      "4733/4733 [==============================] - 285s 60ms/step - loss: 12.1698 - mean_absolute_error: 12.1698 - val_loss: 12.8445 - val_mean_absolute_error: 12.8445\n",
      "Epoch 23/100\n",
      "4733/4733 [==============================] - 280s 59ms/step - loss: 12.1428 - mean_absolute_error: 12.1428 - val_loss: 12.4657 - val_mean_absolute_error: 12.4657\n",
      "Epoch 24/100\n",
      "4733/4733 [==============================] - 279s 59ms/step - loss: 12.1053 - mean_absolute_error: 12.1053 - val_loss: 12.4275 - val_mean_absolute_error: 12.4275\n",
      "Epoch 25/100\n",
      "4733/4733 [==============================] - 278s 59ms/step - loss: 12.0638 - mean_absolute_error: 12.0638 - val_loss: 12.5906 - val_mean_absolute_error: 12.5906\n",
      "Epoch 26/100\n",
      "4733/4733 [==============================] - 278s 59ms/step - loss: 12.0377 - mean_absolute_error: 12.0377 - val_loss: 12.5745 - val_mean_absolute_error: 12.5745\n",
      "Epoch 27/100\n",
      "4733/4733 [==============================] - 281s 59ms/step - loss: 12.0090 - mean_absolute_error: 12.0090 - val_loss: 12.5503 - val_mean_absolute_error: 12.5503\n",
      "Epoch 28/100\n",
      "4733/4733 [==============================] - 277s 58ms/step - loss: 11.9805 - mean_absolute_error: 11.9805 - val_loss: 12.5521 - val_mean_absolute_error: 12.5521\n",
      "Epoch 29/100\n",
      "4733/4733 [==============================] - 279s 59ms/step - loss: 11.9462 - mean_absolute_error: 11.9462 - val_loss: 12.5261 - val_mean_absolute_error: 12.5261\n",
      "Epoch 30/100\n",
      "4733/4733 [==============================] - 282s 60ms/step - loss: 11.9185 - mean_absolute_error: 11.9185 - val_loss: 12.8198 - val_mean_absolute_error: 12.8198\n",
      "Epoch 31/100\n",
      "4733/4733 [==============================] - 286s 60ms/step - loss: 11.8827 - mean_absolute_error: 11.8827 - val_loss: 13.0135 - val_mean_absolute_error: 13.0135\n",
      "Epoch 32/100\n",
      "4733/4733 [==============================] - 281s 59ms/step - loss: 11.8636 - mean_absolute_error: 11.8636 - val_loss: 12.7178 - val_mean_absolute_error: 12.7178\n",
      "Epoch 33/100\n",
      "4733/4733 [==============================] - 284s 60ms/step - loss: 11.8394 - mean_absolute_error: 11.8394 - val_loss: 12.7178 - val_mean_absolute_error: 12.7178\n",
      "Epoch 34/100\n",
      "4733/4733 [==============================] - 289s 61ms/step - loss: 11.8123 - mean_absolute_error: 11.8123 - val_loss: 12.8118 - val_mean_absolute_error: 12.8118\n",
      "Epoch 35/100\n",
      "4733/4733 [==============================] - 288s 61ms/step - loss: 11.7839 - mean_absolute_error: 11.7839 - val_loss: 12.6276 - val_mean_absolute_error: 12.6276\n",
      "Epoch 36/100\n",
      "4733/4733 [==============================] - 288s 61ms/step - loss: 11.7572 - mean_absolute_error: 11.7572 - val_loss: 12.5936 - val_mean_absolute_error: 12.5936\n",
      "1163/1163 [==============================] - 26s 22ms/step - loss: 12.8379 - mean_absolute_error: 12.8379\n",
      "   1/1163 [..............................] - ETA: 23:39"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-19 18:04:35.597704: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:693] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"CPU\" model: \"0\" frequency: 2400 num_cores: 10 environment { key: \"cpu_instruction_set\" value: \"ARM NEON\" } environment { key: \"eigen\" value: \"3.4.90\" } l1_cache_size: 16384 l2_cache_size: 524288 l3_cache_size: 524288 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1163/1163 [==============================] - 27s 22ms/step\n",
      "|                                 |   Mean Absolute Error |      Trade Count |\n",
      "|:--------------------------------|----------------------:|-----------------:|\n",
      "| Entire set                      |                12.838 |      1.16204e+06 |\n",
      "| Dealer-Dealer                   |                13.175 | 438706           |\n",
      "| Bid Side / Dealer-Purchase      |                14.134 | 302777           |\n",
      "| Offered Side / Dealer-Sell      |                11.553 | 420553           |\n",
      "| AAA                             |                12.002 | 190193           |\n",
      "| Investment Grade                |                12.528 | 937855           |\n",
      "| Trade size >= 100k              |                11.099 | 262298           |\n",
      "| Last trade <= 7 days            |                10.957 | 794632           |\n",
      "| 7 days < Last trade <= 14 days  |                13.789 | 109307           |\n",
      "| 14 days < Last trade <= 28 days |                15.924 |  88850           |\n",
      "| 28 days < Last trade            |                19.433 | 169247           |\n",
      "BEGIN save_model\n",
      "file time stamp: 2024-11-19-21-05\n",
      "Uploading model to /Users/mitas/trained_models/yield_spread_with_similar_trades_models/saved_models/saved_model_similar_trades2024-11-19-21-05old_data\n",
      "INFO:tensorflow:Assets written to: /Users/mitas/trained_models/yield_spread_with_similar_trades_models/saved_models/saved_model_similar_trades2024-11-19-21-05old_data/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/mitas/trained_models/yield_spread_with_similar_trades_models/saved_models/saved_model_similar_trades2024-11-19-21-05old_data/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "END save_model. Execution time: 0:01:21.979\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean Absolute Error</th>\n",
       "      <th>Trade Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Entire set</th>\n",
       "      <td>12.838</td>\n",
       "      <td>1162036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dealer-Dealer</th>\n",
       "      <td>13.175</td>\n",
       "      <td>438706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bid Side / Dealer-Purchase</th>\n",
       "      <td>14.134</td>\n",
       "      <td>302777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Offered Side / Dealer-Sell</th>\n",
       "      <td>11.553</td>\n",
       "      <td>420553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAA</th>\n",
       "      <td>12.002</td>\n",
       "      <td>190193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Investment Grade</th>\n",
       "      <td>12.528</td>\n",
       "      <td>937855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trade size &gt;= 100k</th>\n",
       "      <td>11.099</td>\n",
       "      <td>262298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Last trade &lt;= 7 days</th>\n",
       "      <td>10.957</td>\n",
       "      <td>794632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7 days &lt; Last trade &lt;= 14 days</th>\n",
       "      <td>13.789</td>\n",
       "      <td>109307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14 days &lt; Last trade &lt;= 28 days</th>\n",
       "      <td>15.924</td>\n",
       "      <td>88850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28 days &lt; Last trade</th>\n",
       "      <td>19.433</td>\n",
       "      <td>169247</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Mean Absolute Error  Trade Count\n",
       "Entire set                                    12.838      1162036\n",
       "Dealer-Dealer                                 13.175       438706\n",
       "Bid Side / Dealer-Purchase                    14.134       302777\n",
       "Offered Side / Dealer-Sell                    11.553       420553\n",
       "AAA                                           12.002       190193\n",
       "Investment Grade                              12.528       937855\n",
       "Trade size >= 100k                            11.099       262298\n",
       "Last trade <= 7 days                          10.957       794632\n",
       "7 days < Last trade <= 14 days                13.789       109307\n",
       "14 days < Last trade <= 28 days               15.924        88850\n",
       "28 days < Last trade                          19.433       169247"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_model(old_data, '2024-09-30', '_old_data')    # Tuesday 2024-10-01 - Thursday 2024-10-31 is the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set contains 5296659 trades ranging from trade datetimes of 2024-05-01 07:01:05 to 2024-09-30 18:24:32\n",
      "Test set contains 1167232 trades ranging from trade datetimes of 2024-10-01 06:00:01 to 2024-10-31 18:35:10\n",
      "BEGIN create_input\n",
      "END create_input. Execution time: 0:00:26.941\n",
      "BEGIN create_input\n",
      "END create_input. Execution time: 0:00:07.137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-19 18:08:01.546590: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:693] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"CPU\" model: \"0\" frequency: 2400 num_cores: 10 environment { key: \"cpu_instruction_set\" value: \"ARM NEON\" } environment { key: \"eigen\" value: \"3.4.90\" } l1_cache_size: 16384 l2_cache_size: 524288 l3_cache_size: 524288 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4767/4767 [==============================] - ETA: 0s - loss: 31.9674 - mean_absolute_error: 31.9674"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-19 18:12:38.497692: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:693] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"CPU\" model: \"0\" frequency: 2400 num_cores: 10 environment { key: \"cpu_instruction_set\" value: \"ARM NEON\" } environment { key: \"eigen\" value: \"3.4.90\" } l1_cache_size: 16384 l2_cache_size: 524288 l3_cache_size: 524288 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4767/4767 [==============================] - 294s 60ms/step - loss: 31.9674 - mean_absolute_error: 31.9674 - val_loss: 16.1880 - val_mean_absolute_error: 16.1880\n",
      "Epoch 2/100\n",
      "4767/4767 [==============================] - 281s 59ms/step - loss: 14.7372 - mean_absolute_error: 14.7372 - val_loss: 13.1915 - val_mean_absolute_error: 13.1915\n",
      "Epoch 3/100\n",
      "4767/4767 [==============================] - 284s 60ms/step - loss: 13.9429 - mean_absolute_error: 13.9429 - val_loss: 12.9881 - val_mean_absolute_error: 12.9881\n",
      "Epoch 4/100\n",
      "4767/4767 [==============================] - 276s 58ms/step - loss: 13.6047 - mean_absolute_error: 13.6047 - val_loss: 12.5383 - val_mean_absolute_error: 12.5383\n",
      "Epoch 5/100\n",
      "4767/4767 [==============================] - 275s 58ms/step - loss: 13.3703 - mean_absolute_error: 13.3703 - val_loss: 12.3410 - val_mean_absolute_error: 12.3410\n",
      "Epoch 6/100\n",
      "4767/4767 [==============================] - 276s 58ms/step - loss: 13.2059 - mean_absolute_error: 13.2059 - val_loss: 12.3613 - val_mean_absolute_error: 12.3613\n",
      "Epoch 7/100\n",
      "4767/4767 [==============================] - 276s 58ms/step - loss: 13.0762 - mean_absolute_error: 13.0762 - val_loss: 12.4480 - val_mean_absolute_error: 12.4480\n",
      "Epoch 8/100\n",
      "4767/4767 [==============================] - 276s 58ms/step - loss: 12.9587 - mean_absolute_error: 12.9587 - val_loss: 12.0658 - val_mean_absolute_error: 12.0658\n",
      "Epoch 9/100\n",
      "4767/4767 [==============================] - 275s 58ms/step - loss: 12.8584 - mean_absolute_error: 12.8584 - val_loss: 11.9931 - val_mean_absolute_error: 11.9931\n",
      "Epoch 10/100\n",
      "4767/4767 [==============================] - 273s 57ms/step - loss: 12.7733 - mean_absolute_error: 12.7733 - val_loss: 12.1627 - val_mean_absolute_error: 12.1627\n",
      "Epoch 11/100\n",
      "4767/4767 [==============================] - 273s 57ms/step - loss: 12.6847 - mean_absolute_error: 12.6847 - val_loss: 12.0407 - val_mean_absolute_error: 12.0407\n",
      "Epoch 12/100\n",
      "4767/4767 [==============================] - 272s 57ms/step - loss: 12.6141 - mean_absolute_error: 12.6141 - val_loss: 11.9906 - val_mean_absolute_error: 11.9906\n",
      "Epoch 13/100\n",
      "4767/4767 [==============================] - 273s 57ms/step - loss: 12.5534 - mean_absolute_error: 12.5534 - val_loss: 11.8964 - val_mean_absolute_error: 11.8964\n",
      "Epoch 14/100\n",
      "4767/4767 [==============================] - 274s 58ms/step - loss: 12.4917 - mean_absolute_error: 12.4917 - val_loss: 11.8296 - val_mean_absolute_error: 11.8296\n",
      "Epoch 15/100\n",
      "4767/4767 [==============================] - 274s 57ms/step - loss: 12.4346 - mean_absolute_error: 12.4346 - val_loss: 11.9050 - val_mean_absolute_error: 11.9050\n",
      "Epoch 16/100\n",
      "4767/4767 [==============================] - 274s 58ms/step - loss: 12.3855 - mean_absolute_error: 12.3855 - val_loss: 11.7757 - val_mean_absolute_error: 11.7757\n",
      "Epoch 17/100\n",
      "4767/4767 [==============================] - 278s 58ms/step - loss: 12.3339 - mean_absolute_error: 12.3339 - val_loss: 12.0359 - val_mean_absolute_error: 12.0359\n",
      "Epoch 18/100\n",
      "4767/4767 [==============================] - 276s 58ms/step - loss: 12.2894 - mean_absolute_error: 12.2894 - val_loss: 11.9239 - val_mean_absolute_error: 11.9239\n",
      "Epoch 19/100\n",
      "4767/4767 [==============================] - 277s 58ms/step - loss: 12.2323 - mean_absolute_error: 12.2323 - val_loss: 11.8314 - val_mean_absolute_error: 11.8314\n",
      "Epoch 20/100\n",
      "4767/4767 [==============================] - 276s 58ms/step - loss: 12.1926 - mean_absolute_error: 12.1926 - val_loss: 11.8671 - val_mean_absolute_error: 11.8671\n",
      "Epoch 21/100\n",
      "4767/4767 [==============================] - 275s 58ms/step - loss: 12.1568 - mean_absolute_error: 12.1568 - val_loss: 11.8322 - val_mean_absolute_error: 11.8322\n",
      "Epoch 22/100\n",
      "4767/4767 [==============================] - 281s 59ms/step - loss: 12.1164 - mean_absolute_error: 12.1164 - val_loss: 11.7135 - val_mean_absolute_error: 11.7135\n",
      "Epoch 23/100\n",
      "4767/4767 [==============================] - 280s 59ms/step - loss: 12.0773 - mean_absolute_error: 12.0773 - val_loss: 11.6307 - val_mean_absolute_error: 11.6307\n",
      "Epoch 24/100\n",
      "4767/4767 [==============================] - 279s 59ms/step - loss: 12.0436 - mean_absolute_error: 12.0436 - val_loss: 11.7514 - val_mean_absolute_error: 11.7514\n",
      "Epoch 25/100\n",
      "4767/4767 [==============================] - 279s 59ms/step - loss: 12.0085 - mean_absolute_error: 12.0085 - val_loss: 11.6326 - val_mean_absolute_error: 11.6326\n",
      "Epoch 26/100\n",
      "4767/4767 [==============================] - 278s 58ms/step - loss: 11.9726 - mean_absolute_error: 11.9726 - val_loss: 11.8294 - val_mean_absolute_error: 11.8294\n",
      "Epoch 27/100\n",
      "4767/4767 [==============================] - 279s 58ms/step - loss: 11.9381 - mean_absolute_error: 11.9381 - val_loss: 11.8327 - val_mean_absolute_error: 11.8327\n",
      "Epoch 28/100\n",
      "4767/4767 [==============================] - 279s 59ms/step - loss: 11.9042 - mean_absolute_error: 11.9042 - val_loss: 11.6839 - val_mean_absolute_error: 11.6839\n",
      "Epoch 29/100\n",
      "4767/4767 [==============================] - 275s 58ms/step - loss: 11.8695 - mean_absolute_error: 11.8695 - val_loss: 11.6716 - val_mean_absolute_error: 11.6716\n",
      "Epoch 30/100\n",
      "4767/4767 [==============================] - 278s 58ms/step - loss: 11.8509 - mean_absolute_error: 11.8509 - val_loss: 11.9101 - val_mean_absolute_error: 11.9101\n",
      "Epoch 31/100\n",
      "4767/4767 [==============================] - 280s 59ms/step - loss: 11.8145 - mean_absolute_error: 11.8145 - val_loss: 11.8033 - val_mean_absolute_error: 11.8033\n",
      "Epoch 32/100\n",
      "4767/4767 [==============================] - 276s 58ms/step - loss: 11.7920 - mean_absolute_error: 11.7920 - val_loss: 11.7345 - val_mean_absolute_error: 11.7345\n",
      "Epoch 33/100\n",
      "4767/4767 [==============================] - 277s 58ms/step - loss: 11.7608 - mean_absolute_error: 11.7608 - val_loss: 11.7186 - val_mean_absolute_error: 11.7186\n",
      "Epoch 34/100\n",
      "4767/4767 [==============================] - 272s 57ms/step - loss: 11.7255 - mean_absolute_error: 11.7255 - val_loss: 11.7658 - val_mean_absolute_error: 11.7658\n",
      "Epoch 35/100\n",
      "4767/4767 [==============================] - 272s 57ms/step - loss: 11.7062 - mean_absolute_error: 11.7062 - val_loss: 11.7080 - val_mean_absolute_error: 11.7080\n",
      "Epoch 36/100\n",
      "4767/4767 [==============================] - 272s 57ms/step - loss: 11.6902 - mean_absolute_error: 11.6902 - val_loss: 11.6362 - val_mean_absolute_error: 11.6362\n",
      "Epoch 37/100\n",
      "4767/4767 [==============================] - 270s 57ms/step - loss: 11.6568 - mean_absolute_error: 11.6568 - val_loss: 11.8892 - val_mean_absolute_error: 11.8892\n",
      "Epoch 38/100\n",
      "4767/4767 [==============================] - 273s 57ms/step - loss: 11.6373 - mean_absolute_error: 11.6373 - val_loss: 11.8307 - val_mean_absolute_error: 11.8307\n",
      "Epoch 39/100\n",
      "4767/4767 [==============================] - 273s 57ms/step - loss: 11.6090 - mean_absolute_error: 11.6090 - val_loss: 11.6395 - val_mean_absolute_error: 11.6395\n",
      "Epoch 40/100\n",
      "4767/4767 [==============================] - 270s 57ms/step - loss: 11.5895 - mean_absolute_error: 11.5895 - val_loss: 11.7020 - val_mean_absolute_error: 11.7020\n",
      "Epoch 41/100\n",
      "4767/4767 [==============================] - 271s 57ms/step - loss: 11.5604 - mean_absolute_error: 11.5604 - val_loss: 11.6747 - val_mean_absolute_error: 11.6747\n",
      "Epoch 42/100\n",
      "4767/4767 [==============================] - 270s 57ms/step - loss: 11.5383 - mean_absolute_error: 11.5383 - val_loss: 11.7587 - val_mean_absolute_error: 11.7587\n",
      "Epoch 43/100\n",
      "4767/4767 [==============================] - 270s 57ms/step - loss: 11.5142 - mean_absolute_error: 11.5142 - val_loss: 11.8595 - val_mean_absolute_error: 11.8595\n",
      "1168/1168 [==============================] - 23s 20ms/step - loss: 12.8289 - mean_absolute_error: 12.8289\n",
      "   1/1168 [..............................] - ETA: 23:42"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-19 21:26:02.693631: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:693] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"CPU\" model: \"0\" frequency: 2400 num_cores: 10 environment { key: \"cpu_instruction_set\" value: \"ARM NEON\" } environment { key: \"eigen\" value: \"3.4.90\" } l1_cache_size: 16384 l2_cache_size: 524288 l3_cache_size: 524288 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1168/1168 [==============================] - 25s 20ms/step\n",
      "|                                 |   Mean Absolute Error |      Trade Count |\n",
      "|:--------------------------------|----------------------:|-----------------:|\n",
      "| Entire set                      |                12.829 |      1.16723e+06 |\n",
      "| Dealer-Dealer                   |                13.188 | 439702           |\n",
      "| Bid Side / Dealer-Purchase      |                14.255 | 302799           |\n",
      "| Offered Side / Dealer-Sell      |                11.44  | 424731           |\n",
      "| AAA                             |                11.924 | 176956           |\n",
      "| Investment Grade                |                12.584 | 862236           |\n",
      "| Trade size >= 100k              |                10.861 | 266471           |\n",
      "| Last trade <= 7 days            |                10.952 | 800077           |\n",
      "| 7 days < Last trade <= 14 days  |                14.261 | 109229           |\n",
      "| 14 days < Last trade <= 28 days |                16.573 |  88791           |\n",
      "| 28 days < Last trade            |                18.817 | 169135           |\n",
      "BEGIN save_model\n",
      "file time stamp: 2024-11-20-00-26\n",
      "Uploading model to /Users/mitas/trained_models/yield_spread_with_similar_trades_models/saved_models/saved_model_similar_trades2024-11-20-00-26old_data\n",
      "INFO:tensorflow:Assets written to: /Users/mitas/trained_models/yield_spread_with_similar_trades_models/saved_models/saved_model_similar_trades2024-11-20-00-26old_data/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/mitas/trained_models/yield_spread_with_similar_trades_models/saved_models/saved_model_similar_trades2024-11-20-00-26old_data/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "END save_model. Execution time: 0:00:29.519\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean Absolute Error</th>\n",
       "      <th>Trade Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Entire set</th>\n",
       "      <td>12.829</td>\n",
       "      <td>1167232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dealer-Dealer</th>\n",
       "      <td>13.188</td>\n",
       "      <td>439702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bid Side / Dealer-Purchase</th>\n",
       "      <td>14.255</td>\n",
       "      <td>302799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Offered Side / Dealer-Sell</th>\n",
       "      <td>11.440</td>\n",
       "      <td>424731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAA</th>\n",
       "      <td>11.924</td>\n",
       "      <td>176956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Investment Grade</th>\n",
       "      <td>12.584</td>\n",
       "      <td>862236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trade size &gt;= 100k</th>\n",
       "      <td>10.861</td>\n",
       "      <td>266471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Last trade &lt;= 7 days</th>\n",
       "      <td>10.952</td>\n",
       "      <td>800077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7 days &lt; Last trade &lt;= 14 days</th>\n",
       "      <td>14.261</td>\n",
       "      <td>109229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14 days &lt; Last trade &lt;= 28 days</th>\n",
       "      <td>16.573</td>\n",
       "      <td>88791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28 days &lt; Last trade</th>\n",
       "      <td>18.817</td>\n",
       "      <td>169135</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Mean Absolute Error  Trade Count\n",
       "Entire set                                    12.829      1167232\n",
       "Dealer-Dealer                                 13.188       439702\n",
       "Bid Side / Dealer-Purchase                    14.255       302799\n",
       "Offered Side / Dealer-Sell                    11.440       424731\n",
       "AAA                                           11.924       176956\n",
       "Investment Grade                              12.584       862236\n",
       "Trade size >= 100k                            10.861       266471\n",
       "Last trade <= 7 days                          10.952       800077\n",
       "7 days < Last trade <= 14 days                14.261       109229\n",
       "14 days < Last trade <= 28 days               16.573        88791\n",
       "28 days < Last trade                          18.817       169135"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_model(new_data, '2024-09-30', '_new_data')    # Tuesday 2024-10-01 - Thursday 2024-10-31 is the test set"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
