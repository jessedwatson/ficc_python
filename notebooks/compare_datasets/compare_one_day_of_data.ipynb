{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare One Day of Data\n",
    "\n",
    "Created by Mitas Ray on 2024-12-09.\n",
    "\n",
    "Last edited by Mitas Ray on 2024-12-09.\n",
    "\n",
    "This notebook investigates three anomalies based on a single day of data for two datasets: (1) current data used for automated training, and (2) new data to be used for automated training. The anomalies are: (1) the data in the sets have minor differences, (2) the same model has vastly different predictions on these two datasets, (3) a model that was trained on just two epochs has very similar accuracy to a model that was trained on 100 epochs. The procedure is to \n",
    "1. download both datasets and isolate the single day\n",
    "2. download the archived models\n",
    "3. compare the accuracy results of the archived models on these datasets\n",
    "\n",
    "To run the notebook, use Python 3.10 (Python 3.12 does not work), and\n",
    "- on linux: use `ficc_python/requirements_py310_linux_jupyter.txt`\n",
    "- on mac: use `ficc_python/requirements_py310_mac_jupyter.txt`\n",
    "\n",
    "Note: This notebook **requires at least 80 GB of RAM** on a VM. On a MacBook Pro M1 Max with 32 GB of RAM, it can still run because swap memory allows the system to use additional storage space to supplement the required memory.\n",
    "\n",
    "Change the following files and/or variables to enable credentials and the correct directories:\n",
    "- `automated_training_auxiliary_functions.py::get_creds(...)` to be the location of the credentials file\n",
    "- `automated_training_auxiliary_variables.py::WORKING_DIRECTORY` to be the location of the current working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loads the autoreload extension\n",
    "%load_ext autoreload\n",
    "# automatically reloads all imported modules when their source code changes\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 5 workers.\n",
      "INFO: Pandarallel will use standard multiprocessing data transfer (pipe) to transfer data between the main process and workers.\n",
      "Initialized pandarallel with 5 cores\n",
      "INFO: Pandarallel will run on 5 workers.\n",
      "INFO: Pandarallel will use standard multiprocessing data transfer (pipe) to transfer data between the main process and workers.\n",
      "Initialized pandarallel with 5 cores\n",
      "INFO: Pandarallel will run on 5 workers.\n",
      "INFO: Pandarallel will use standard multiprocessing data transfer (pipe) to transfer data between the main process and workers.\n",
      "Initialized pandarallel with 5 cores\n",
      "In PRODUCTION mode (to change to TESTING mode, set `TESTING` to `True`); all files and models will be saved and NUM_EPOCHS=100\n",
      "INFO: Pandarallel will run on 5 workers.\n",
      "INFO: Pandarallel will use standard multiprocessing data transfer (pipe) to transfer data between the main process and workers.\n",
      "Initialized pandarallel with 5 cores\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "\n",
    "\n",
    "# importing from parent directory: https://stackoverflow.com/questions/714063/importing-modules-from-parent-folder\n",
    "import sys\n",
    "sys.path.insert(0, '../../')\n",
    "\n",
    "\n",
    "from automated_training_auxiliary_variables import WORKING_DIRECTORY\n",
    "from automated_training_auxiliary_functions import STORAGE_CLIENT, create_input, load_model, create_summary_of_results\n",
    "from ficc.utils.gcp_storage_functions import download_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOMATED_TRAINING_BUCKET = 'automated_training'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_for_automated_training_and_isolate_to_single_dates(old_or_new: str, dates: list) -> pd.DataFrame:\n",
    "    assert old_or_new in ('old', 'new')\n",
    "    df_list = []\n",
    "    df_downloaded_from_google_cloud_storage = {}\n",
    "    for date in dates:\n",
    "        pickle_file_path = f'{WORKING_DIRECTORY}/files/{old_or_new}_data_{date}.pkl'\n",
    "        if os.path.exists(pickle_file_path):\n",
    "            print(f'Loading pickle file from {pickle_file_path}')\n",
    "            df_list.append(pd.read_pickle(pickle_file_path))\n",
    "        else:\n",
    "            print(f'Could not find pickle file in {pickle_file_path}, so creating it now')\n",
    "            suffix = '' if old_or_new == 'old' else '_v2'\n",
    "            google_cloud_storage_file_name =  f'processed_data_yield_spread_with_similar_trades{suffix}.pkl'\n",
    "            if google_cloud_storage_file_name not in df_downloaded_from_google_cloud_storage:\n",
    "                df = download_data(STORAGE_CLIENT, AUTOMATED_TRAINING_BUCKET, google_cloud_storage_file_name)\n",
    "                df_downloaded_from_google_cloud_storage[google_cloud_storage_file_name] = df\n",
    "            else:\n",
    "                df = df_downloaded_from_google_cloud_storage[google_cloud_storage_file_name]\n",
    "            \n",
    "            df = df[df['trade_date'] == date]\n",
    "            df.to_pickle(pickle_file_path)\n",
    "            df_list.append(df)\n",
    "    return df_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not find pickle file in /Users/mitas/ficc/ficc_python/notebooks/compare_datasets/files/old_data_2024-12-06.pkl, so creating it now\n"
     ]
    }
   ],
   "source": [
    "current_df_on_2024_12_06 = get_data_for_automated_training_and_isolate_to_single_dates('old', ['2024-12-06'])\n",
    "new_df_on_2024_12_06 = get_data_for_automated_training_and_isolate_to_single_dates('new', ['2024-12-06'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anomaly 1: different data in the two datasets\n",
    "Check which RTRS control numbers are differing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Number of items in the current df: {len(current_df_on_2024_12_06)}')\n",
    "print(f'Number of items in the new df: {len(new_df_on_2024_12_06)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_df_on_2024_12_06_rtrs_control_numbers = set(current_df_on_2024_12_06['rtrs_control_number'].tolist())\n",
    "new_df_on_2024_12_06_rtrs_control_numbers = set(new_df_on_2024_12_06['rtrs_control_number'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'RTRS control numbers in the current df but not in the new df: {current_df_on_2024_12_06_rtrs_control_numbers - new_df_on_2024_12_06_rtrs_control_numbers}')\n",
    "print(f'RTRS control numbers in the new df but not in the current df: {new_df_on_2024_12_06_rtrs_control_numbers - current_df_on_2024_12_06_rtrs_control_numbers}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anomaly 2: same model has vastly different predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similar_trades_model_2024_12_06, _ = load_model('2024-12-06', 'yield_spread_with_similar_trades')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_summary_of_results(similar_trades_model_2024_12_06, current_df_on_2024_12_06, *create_input(current_df_on_2024_12_06), print_results=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_summary_of_results(similar_trades_model_2024_12_06, new_df_on_2024_12_06, *create_input(current_df_on_2024_12_06), print_results=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anomaly 3: test model has similar accuracy to production model\n",
    "The v2 yield spread with similar trades model trained on 2024-12-06 used only 2 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similar_trades_model_2024_12_09, _ = load_model('2024-12-09', 'yield_spread_with_similar_trades')\n",
    "similar_trades_model_v2_2024_12_09 = keras.models.load_model(os.path.join(AUTOMATED_TRAINING_BUCKET, f'similar-trades-v2-model-2024-12-09'))    # create path of the form: <bucket>/<model>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
